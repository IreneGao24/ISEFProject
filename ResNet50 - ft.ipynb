{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d12f34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import openslide\n",
    "from skimage.color import rgb2hsv\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import pathlib\n",
    "import tables\n",
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import kl_div, softmax, log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cf896e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_img', 'test_label', 'train_img', 'train_label', 'val_img', 'val_label']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_path = '/home/irene/Downloads/luadlusc.hdf5'\n",
    "file = h5py.File(hdf5_path, \"r\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95684110",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean,rgb_std = (0.485, 0.456, 0.406),(0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bd5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, h5_path, set_name, transform = None):\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset = None\n",
    "        self.transform = transform\n",
    "        self.file_path  = h5_path\n",
    "        self.set = set_name\n",
    "        \n",
    "        str_name = self.set + \"_img\"\n",
    "        \n",
    "        file = h5py.File(h5_path, \"r\")\n",
    "        self.dataset_len = len(file[str_name])\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(rgb_mean,rgb_std)\n",
    "            ])\n",
    "        \n",
    "    def __getitem__(self, index): #to enable indexing\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.imgs = h5py.File(self.file_path, 'r')[self.set + \"_img\"]\n",
    "            self.labels = h5py.File(self.file_path, 'r')[self.set + \"_label\"]\n",
    "            \n",
    "            cur_img = self.imgs[index]\n",
    "            PIL_image = Image.fromarray(np.uint8(cur_img)).convert('RGB')#3 channels don't need alpha channel network input\n",
    "            image = self.transform(PIL_image)\n",
    "            label = self.labels[index].astype('float32')\n",
    "            \n",
    "            \n",
    "        return (image,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d175902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "train_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"train\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "val_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"val\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "test_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"test\"), batch_size=8,shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c365801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"resnet50\", pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, out_dim)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train_valid_model (net,loaders,max_epochs = 20):\n",
    "    best_acc = 0.0 \n",
    "    for epoch in range (max_epochs):\n",
    "        for phase in ['train','val']:\n",
    "            iterator = iter(loaders[phase])\n",
    "            total_step = len(loaders[phase])\n",
    "            print('Phase {}'.format(phase))\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "            predictions_all = []\n",
    "            label_all = []\n",
    "            probs_all = []\n",
    "            for step in range(total_step-1): #iterate each batch\n",
    "                images,labels = next(iterator) # CUDA computation\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = net(images)\n",
    "                loss = criterion(output,labels)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(output, dim=1) # probabilities\n",
    "                \n",
    "                running_loss +=loss.item()\n",
    "                _, preds = torch.max(output.data,1)\n",
    "                \n",
    "                running_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                if len(predictions_all) == 0:\n",
    "                    predictions_all = preds.detach().cpu().numpy()\n",
    "                    label_all = labels.detach().cpu().numpy()\n",
    "                    probs_all = probs.detach().cpu().numpy()\n",
    "                else:\n",
    "                    predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                    probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "                    label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "                    \n",
    "            phase_loss = running_loss / len(loaders[phase])\n",
    "            phase_acc = running_correct/len(label_all.flatten())\n",
    "            if phase == 'val':\n",
    "                y_true = label_all.flatten()\n",
    "                y_pred = predictions_all.flatten()\n",
    "                print(\"validating...\")\n",
    "                print(len(y_true))\n",
    "                print(len(y_pred))\n",
    "                print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "            if phase == 'val' and phase_acc > best_acc:\n",
    "                \n",
    "                best_acc = phase_acc\n",
    "                import copy \n",
    "                \n",
    "                best_model_state_dict = copy.deepcopy(net.state_dict())\n",
    "                torch.save(best_model_state_dict,'resnet50best_model.pth')\n",
    "                \n",
    "            print('PHASE {} Loss: {:.4f} Acc: {:.4f}'.format(phase, phase_loss, phase_acc))\n",
    "    net.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    return net \n",
    "            \n",
    "       \n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6efcc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model (net, test_loader, a_device = None):\n",
    "    iterator = iter(test_loader)\n",
    "    total_step = len(test_loader)\n",
    "    \n",
    "    print(total_step)\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        total_0,total_1 = 0,0\n",
    "        hit_0 = 0\n",
    "        hit_1 = 0\n",
    "        label_all = []\n",
    "        probs_all = []\n",
    "        predictions_all = []\n",
    "        for step in range(total_step-1):\n",
    "            images,labels = next(iterator)\n",
    "            images.to(a_device)\n",
    "            labels.to(a_device)\n",
    "            total_0 += labels.tolist().count(0)\n",
    "            total_1 += labels.tolist().count(1)\n",
    "            print(labels.shape)\n",
    "            images = images.to(a_device)\n",
    "            labels = labels.to(device=a_device, dtype=torch.int64)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            output = net(images)\n",
    "            loss = criterion(output,labels)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "            _, preds = torch.max(output.data,1)\n",
    "            \n",
    "            equals = preds == labels.view(*preds.shape)\n",
    "            if(len(label_all) ==0):\n",
    "                predictions_all = preds.detach().cpu().numpy()\n",
    "                label_all = labels.detach().cpu().numpy()\n",
    "                probs_all = probs.detach().cpu().numpy()\n",
    "            else:\n",
    "                predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "                probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "\n",
    "            all_hits = equals.view(equals.shape[0]).tolist() \n",
    "            all_corrects = labels[all_hits]\n",
    "            \n",
    "            hit_0 += all_corrects.tolist().count(0)\n",
    "            hit_1 += all_corrects.tolist().count(1)\n",
    " \n",
    "        \n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "        print(len(label_all.flatten()))\n",
    "        label_all = label_all.flatten()\n",
    "        predictions_all = predictions_all.flatten()\n",
    "        phase_loss = running_loss / len(test_loader)\n",
    "        phase_acc = running_corrects/len(label_all.flatten())\n",
    "        print('Test Loss: {:.4f} Acc: {:.4f}'.format(phase_loss, phase_acc))\n",
    "        \n",
    "        print(hit_0, ' / ',total_0)\n",
    "        print(hit_1, ' / ',total_1)\n",
    "                \n",
    "            \n",
    "    return label_all, probs_all, predictions_all #add this later\n",
    "                \n",
    "        #y_test --> label, y_score --> probs all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001dd949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.4042 Acc: 0.8057\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.935     0.898     0.916      4528\n",
      "           1      0.917     0.947     0.932      5400\n",
      "\n",
      "    accuracy                          0.925      9928\n",
      "   macro avg      0.926     0.923     0.924      9928\n",
      "weighted avg      0.925     0.925     0.925      9928\n",
      "\n",
      "PHASE val Loss: 0.1870 Acc: 0.9250\n",
      "Phase train\n",
      "PHASE train Loss: 0.2298 Acc: 0.9042\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.951     0.958     0.955      4529\n",
      "           1      0.964     0.959     0.962      5399\n",
      "\n",
      "    accuracy                          0.958      9928\n",
      "   macro avg      0.958     0.958     0.958      9928\n",
      "weighted avg      0.958     0.958     0.958      9928\n",
      "\n",
      "PHASE val Loss: 0.1031 Acc: 0.9584\n",
      "Phase train\n",
      "PHASE train Loss: 0.1501 Acc: 0.9412\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.964     0.964      4529\n",
      "           1      0.969     0.970     0.970      5399\n",
      "\n",
      "    accuracy                          0.967      9928\n",
      "   macro avg      0.967     0.967     0.967      9928\n",
      "weighted avg      0.967     0.967     0.967      9928\n",
      "\n",
      "PHASE val Loss: 0.0853 Acc: 0.9669\n",
      "Phase train\n",
      "PHASE train Loss: 0.1103 Acc: 0.9575\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.979     0.978      4528\n",
      "           1      0.982     0.981     0.981      5400\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.980     0.980     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.0544 Acc: 0.9798\n",
      "Phase train\n",
      "PHASE train Loss: 0.0804 Acc: 0.9701\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.936     0.987     0.960      4528\n",
      "           1      0.988     0.943     0.965      5400\n",
      "\n",
      "    accuracy                          0.963      9928\n",
      "   macro avg      0.962     0.965     0.963      9928\n",
      "weighted avg      0.964     0.963     0.963      9928\n",
      "\n",
      "PHASE val Loss: 0.1026 Acc: 0.9629\n",
      "Phase train\n",
      "PHASE train Loss: 0.0690 Acc: 0.9751\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.987     0.981      4528\n",
      "           1      0.989     0.979     0.984      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0511 Acc: 0.9829\n",
      "Phase train\n",
      "PHASE train Loss: 0.0534 Acc: 0.9805\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.988     0.985      4529\n",
      "           1      0.990     0.985     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0357 Acc: 0.9862\n",
      "Phase train\n",
      "PHASE train Loss: 0.0445 Acc: 0.9840\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.983     0.984      4529\n",
      "           1      0.986     0.987     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0474 Acc: 0.9852\n",
      "Phase train\n",
      "PHASE train Loss: 0.0361 Acc: 0.9876\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.989     0.983      4528\n",
      "           1      0.990     0.981     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0431 Acc: 0.9842\n",
      "Phase train\n",
      "PHASE train Loss: 0.0357 Acc: 0.9871\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.988     0.985      4529\n",
      "           1      0.990     0.984     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0416 Acc: 0.9859\n",
      "Phase train\n",
      "PHASE train Loss: 0.0303 Acc: 0.9898\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.992     0.987      4529\n",
      "           1      0.993     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0389 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0256 Acc: 0.9905\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.958     0.973      4529\n",
      "           1      0.965     0.992     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.978     0.975     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.0730 Acc: 0.9761\n",
      "Phase train\n",
      "PHASE train Loss: 0.0307 Acc: 0.9888\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.981     0.986      4529\n",
      "           1      0.984     0.992     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0420 Acc: 0.9873\n",
      "Phase train\n",
      "PHASE train Loss: 0.0240 Acc: 0.9915\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.970     0.981      4528\n",
      "           1      0.975     0.994     0.985      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.984     0.982     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0500 Acc: 0.9831\n",
      "Phase train\n",
      "PHASE train Loss: 0.0200 Acc: 0.9929\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.995     0.986      4528\n",
      "           1      0.996     0.981     0.988      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.987      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0437 Acc: 0.9875\n",
      "Phase train\n",
      "PHASE train Loss: 0.0197 Acc: 0.9936\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.991     0.984      4529\n",
      "           1      0.993     0.980     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.984     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0497 Acc: 0.9850\n",
      "Phase train\n",
      "PHASE train Loss: 0.0181 Acc: 0.9934\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.981     0.989      4529\n",
      "           1      0.984     0.998     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.989     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0345 Acc: 0.9898\n",
      "Phase train\n",
      "PHASE train Loss: 0.0187 Acc: 0.9939\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.987     0.986      4529\n",
      "           1      0.989     0.987     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0479 Acc: 0.9869\n",
      "Phase train\n",
      "PHASE train Loss: 0.0155 Acc: 0.9946\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.981     0.988      4528\n",
      "           1      0.984     0.995     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0423 Acc: 0.9887\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0111 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.994     0.992      4528\n",
      "           1      0.995     0.992     0.993      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0248 Acc: 0.9925\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0123 Acc: 0.9957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.989     0.989      4528\n",
      "           1      0.991     0.990     0.990      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0354 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0149 Acc: 0.9951\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4529\n",
      "           1      0.993     0.985     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0409 Acc: 0.9882\n",
      "Phase train\n",
      "PHASE train Loss: 0.0094 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.991     0.992      4528\n",
      "           1      0.993     0.995     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0249 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0154 Acc: 0.9945\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.981     0.986      4529\n",
      "           1      0.985     0.992     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0512 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0138 Acc: 0.9952\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.980     0.986      4529\n",
      "           1      0.983     0.994     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.987     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0513 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0125 Acc: 0.9958\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.991     0.988      4528\n",
      "           1      0.992     0.988     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0387 Acc: 0.9890\n",
      "Phase train\n",
      "PHASE train Loss: 0.0109 Acc: 0.9960\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.993     0.994     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0249 Acc: 0.9928\n",
      "Phase train\n",
      "PHASE train Loss: 0.0084 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.996     0.991      4529\n",
      "           1      0.996     0.989     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0254 Acc: 0.9920\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0078 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.990     0.992      4529\n",
      "           1      0.992     0.995     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.992     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0273 Acc: 0.9926\n",
      "Phase train\n",
      "PHASE train Loss: 0.0079 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.989     0.991      4529\n",
      "           1      0.991     0.995     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0257 Acc: 0.9921\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0175 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0199 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.994      4528\n",
      "           1      0.995     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0190 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0104 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4528\n",
      "           1      0.992     0.994     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0278 Acc: 0.9920\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.911     0.996     0.952      4529\n",
      "           1      0.996     0.919     0.956      5399\n",
      "\n",
      "    accuracy                          0.954      9928\n",
      "   macro avg      0.954     0.957     0.954      9928\n",
      "weighted avg      0.958     0.954     0.954      9928\n",
      "\n",
      "PHASE val Loss: 0.1613 Acc: 0.9541\n",
      "Phase train\n",
      "PHASE train Loss: 0.0116 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.984     0.989      4529\n",
      "           1      0.987     0.996     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0322 Acc: 0.9903\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.985     0.989      4528\n",
      "           1      0.987     0.994     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0369 Acc: 0.9899\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0058 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.977     0.985      4528\n",
      "           1      0.981     0.994     0.988      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.987     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0485 Acc: 0.9864\n",
      "Phase train\n",
      "PHASE train Loss: 0.0100 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.988     0.992      4528\n",
      "           1      0.990     0.996     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.993     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0244 Acc: 0.9923\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0056 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.994     0.992      4528\n",
      "           1      0.995     0.991     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9923\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.989     0.992      4529\n",
      "           1      0.991     0.996     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.992     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0246 Acc: 0.9926\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4529\n",
      "           1      0.994     0.992     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0284 Acc: 0.9928\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.992     0.987      4528\n",
      "           1      0.993     0.984     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0427 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0094 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.983     0.988      4529\n",
      "           1      0.986     0.994     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0383 Acc: 0.9890\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.989     0.989      4528\n",
      "           1      0.990     0.991     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0341 Acc: 0.9899\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.995     0.992      4529\n",
      "           1      0.996     0.990     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0273 Acc: 0.9923\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.993     0.993      4528\n",
      "           1      0.994     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0199 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.992     0.985      4528\n",
      "           1      0.993     0.982     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.987     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0456 Acc: 0.9862\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.993      4528\n",
      "           1      0.994     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0250 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.991     0.993      4528\n",
      "           1      0.992     0.996     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0219 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0080 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.985     0.990      4529\n",
      "           1      0.988     0.995     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.990     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0351 Acc: 0.9906\n",
      "Phase train\n",
      "PHASE train Loss: 0.0112 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.994     0.994      4528\n",
      "           1      0.995     0.995     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0185 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4528\n",
      "           1      0.993     0.985     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0417 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0113 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0251 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.991     0.990      4528\n",
      "           1      0.992     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0310 Acc: 0.9906\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.967     0.977      4529\n",
      "           1      0.973     0.989     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.980     0.978     0.979      9928\n",
      "weighted avg      0.979     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.0821 Acc: 0.9791\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.996     0.993      4529\n",
      "           1      0.997     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0239 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0037 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4528\n",
      "           1      0.997     0.995     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.996     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0154 Acc: 0.9955\n",
      "Phase train\n",
      "PHASE train Loss: 0.0039 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.993     0.991      4529\n",
      "           1      0.994     0.991     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9921\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.986     0.988      4528\n",
      "           1      0.988     0.993     0.990      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0319 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.995     0.991      4529\n",
      "           1      0.996     0.989     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0275 Acc: 0.9921\n",
      "Phase train\n",
      "PHASE train Loss: 0.0039 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.983     0.989      4529\n",
      "           1      0.986     0.996     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0312 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0057 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.991     0.993      4528\n",
      "           1      0.993     0.996     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.993     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0215 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0032 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.993     0.994      4528\n",
      "           1      0.994     0.996     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.994     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0219 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0041 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.989     0.991      4529\n",
      "           1      0.991     0.994     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0292 Acc: 0.9917\n",
      "Phase train\n",
      "PHASE train Loss: 0.0060 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4529\n",
      "           1      0.993     0.985     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0471 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0103 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.991     0.992      4529\n",
      "           1      0.992     0.995     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0248 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0031 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.992     0.993      4529\n",
      "           1      0.993     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0298 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0034 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.994      4528\n",
      "           1      0.995     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0230 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0021 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.992      4528\n",
      "           1      0.996     0.991     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0313 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0025 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.990     0.992      4528\n",
      "           1      0.992     0.996     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0264 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.977     0.985      4528\n",
      "           1      0.981     0.995     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.986     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0434 Acc: 0.9868\n",
      "Phase train\n",
      "PHASE train Loss: 0.0067 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.991     0.991      4529\n",
      "           1      0.992     0.994     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0316 Acc: 0.9921\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.992     0.991      4529\n",
      "           1      0.993     0.992     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0319 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.998     0.986      4529\n",
      "           1      0.998     0.978     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.988     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0517 Acc: 0.9870\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0066 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.984     0.989      4529\n",
      "           1      0.987     0.996     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0291 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0098 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.992     0.994      4529\n",
      "           1      0.993     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0229 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.992     0.992      4529\n",
      "           1      0.994     0.992     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0313 Acc: 0.9922\n",
      "Phase train\n",
      "PHASE train Loss: 0.0026 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.990     0.992      4529\n",
      "           1      0.992     0.996     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0284 Acc: 0.9932\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0058 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.991     0.988      4528\n",
      "           1      0.992     0.988     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0395 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.992     0.993      4529\n",
      "           1      0.994     0.995     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0218 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0067 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.993      4528\n",
      "           1      0.995     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0204 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.989     0.991      4529\n",
      "           1      0.991     0.995     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0282 Acc: 0.9922\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.990      4528\n",
      "           1      0.993     0.991     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0297 Acc: 0.9911\n",
      "Phase train\n",
      "PHASE train Loss: 0.0031 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4528\n",
      "           1      0.994     0.992     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0260 Acc: 0.9924\n",
      "Phase train\n",
      "PHASE train Loss: 0.0087 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.991     0.990      4528\n",
      "           1      0.992     0.991     0.991      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0377 Acc: 0.9907\n",
      "Phase train\n",
      "PHASE train Loss: 0.0059 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.994     0.994      4529\n",
      "           1      0.995     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0185 Acc: 0.9949\n",
      "Phase train\n",
      "PHASE train Loss: 0.0039 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.990     0.990      4529\n",
      "           1      0.992     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0353 Acc: 0.9908\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.988     0.988      4529\n",
      "           1      0.990     0.990     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0467 Acc: 0.9889\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.991     0.987      4529\n",
      "           1      0.992     0.986     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0482 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.985     0.990      4528\n",
      "           1      0.987     0.997     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0315 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.996     0.993      4529\n",
      "           1      0.996     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0233 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.992     0.990      4529\n",
      "           1      0.993     0.989     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.991     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0340 Acc: 0.9904\n",
      "Phase train\n",
      "PHASE train Loss: 0.0079 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.993     0.987      4528\n",
      "           1      0.994     0.985     0.989      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0465 Acc: 0.9885\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0086 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.994     0.993     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0254 Acc: 0.9928\n",
      "Phase train\n",
      "PHASE train Loss: 0.0060 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.997     0.993      4529\n",
      "           1      0.998     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0221 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0030 Acc: 0.9990\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.995      4529\n",
      "           1      0.996     0.995     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0213 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0078 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.994     0.992      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.992     0.993      4529\n",
      "           1      0.993     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0237 Acc: 0.9941\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0032 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.992      4529\n",
      "           1      0.996     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0262 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0028 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.992     0.993      4528\n",
      "           1      0.993     0.996     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0217 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0020 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.993     0.994      4529\n",
      "           1      0.994     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0212 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0056 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0277 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.994     0.991      4529\n",
      "           1      0.995     0.991     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9921\n",
      "Phase train\n",
      "PHASE train Loss: 0.0057 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.988     0.990      4528\n",
      "           1      0.990     0.994     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0338 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.994      4529\n",
      "           1      0.995     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0192 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0042 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.992     0.993      4528\n",
      "           1      0.993     0.995     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.993     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0211 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0036 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.985     0.989      4529\n",
      "           1      0.988     0.994     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0361 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0248 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0023 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.994     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0294 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.990     0.989      4529\n",
      "           1      0.991     0.990     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0434 Acc: 0.9900\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.991     0.990      4529\n",
      "           1      0.993     0.990     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0385 Acc: 0.9904\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0086 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.991     0.993      4528\n",
      "           1      0.993     0.996     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0204 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.987     0.990      4529\n",
      "           1      0.989     0.995     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0328 Acc: 0.9913\n",
      "Phase train\n",
      "PHASE train Loss: 0.0050 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0229 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.992     0.988      4528\n",
      "           1      0.994     0.986     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0352 Acc: 0.9892\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.995     0.990      4529\n",
      "           1      0.996     0.987     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0286 Acc: 0.9906\n",
      "Phase train\n",
      "PHASE train Loss: 0.0035 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0182 Acc: 0.9947\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0029 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0234 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0059 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.994     0.994      4529\n",
      "           1      0.995     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0188 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.995     0.991      4529\n",
      "           1      0.996     0.990     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0263 Acc: 0.9920\n",
      "Phase train\n",
      "PHASE train Loss: 0.0089 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.982     0.986      4528\n",
      "           1      0.985     0.992     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0564 Acc: 0.9874\n",
      "Phase train\n",
      "PHASE train Loss: 0.0084 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.993     0.990      4529\n",
      "           1      0.994     0.989     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0303 Acc: 0.9910\n",
      "Phase train\n",
      "PHASE train Loss: 0.0087 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.995     0.990      4529\n",
      "           1      0.996     0.987     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0340 Acc: 0.9907\n",
      "Phase train\n",
      "PHASE train Loss: 0.0057 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4529\n",
      "           1      0.991     0.994     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0271 Acc: 0.9918\n",
      "Phase train\n",
      "PHASE train Loss: 0.0060 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.992     0.992      4528\n",
      "           1      0.993     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0221 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0023 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.983     0.989      4529\n",
      "           1      0.986     0.997     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.991     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0307 Acc: 0.9904\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.997     0.993      4528\n",
      "           1      0.997     0.991     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0227 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.992     0.991      4528\n",
      "           1      0.993     0.993     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0309 Acc: 0.9921\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.980     0.986      4529\n",
      "           1      0.984     0.993     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0797 Acc: 0.9871\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.993      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0216 Acc: 0.9933\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0035 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.989     0.992      4529\n",
      "           1      0.991     0.996     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.992     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0260 Acc: 0.9927\n",
      "Phase train\n",
      "PHASE train Loss: 0.0032 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.993     0.994      4529\n",
      "           1      0.994     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.995     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0198 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0024 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.990     0.993      4529\n",
      "           1      0.992     0.996     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0229 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0017 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.995     0.995      4529\n",
      "           1      0.996     0.996     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0178 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0018 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.997     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0209 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.987     0.986      4528\n",
      "           1      0.989     0.986     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0424 Acc: 0.9868\n",
      "Phase train\n",
      "PHASE train Loss: 0.0113 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.993     0.989      4528\n",
      "           1      0.994     0.987     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0334 Acc: 0.9898\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0010 Acc: 0.9998\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.994     0.995      4529\n",
      "           1      0.995     0.996     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0154 Acc: 0.9955\n",
      "Phase train\n",
      "PHASE train Loss: 0.0029 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.994     0.995      4529\n",
      "           1      0.995     0.997     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0190 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0034 Acc: 0.9990\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.991     0.991      4529\n",
      "           1      0.992     0.992     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0280 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.991     0.992      4529\n",
      "           1      0.992     0.994     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.992     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0234 Acc: 0.9926\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.996     0.991      4529\n",
      "           1      0.997     0.988     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0304 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.989     0.989      4528\n",
      "           1      0.991     0.991     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0458 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0089 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.989     0.990      4529\n",
      "           1      0.990     0.992     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.990     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0326 Acc: 0.9906\n",
      "Phase train\n",
      "PHASE train Loss: 0.0075 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.995     0.980      4529\n",
      "           1      0.995     0.971     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0719 Acc: 0.9819\n",
      "Phase train\n",
      "PHASE train Loss: 0.0083 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.983     0.986      4529\n",
      "           1      0.986     0.991     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.987     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0415 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0042 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.994     0.993     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0283 Acc: 0.9927\n",
      "Phase train\n",
      "PHASE train Loss: 0.0110 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.991     0.991      4528\n",
      "           1      0.993     0.992     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0264 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.996     0.993      4529\n",
      "           1      0.997     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9932\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0078 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.987     0.988      4529\n",
      "           1      0.989     0.991     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0362 Acc: 0.9893\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.993     0.987      4529\n",
      "           1      0.994     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0423 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.993     0.988      4529\n",
      "           1      0.994     0.986     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0381 Acc: 0.9890\n",
      "Phase train\n",
      "PHASE train Loss: 0.0049 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.996     0.991      4529\n",
      "           1      0.996     0.988     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0288 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0049 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.994     0.991      4528\n",
      "           1      0.995     0.989     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0285 Acc: 0.9913\n",
      "Phase train\n",
      "PHASE train Loss: 0.0107 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.986     0.988      4529\n",
      "           1      0.988     0.992     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0314 Acc: 0.9892\n",
      "Phase train\n",
      "PHASE train Loss: 0.0090 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.964     0.979      4528\n",
      "           1      0.970     0.995     0.983      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.979     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0582 Acc: 0.9808\n",
      "Phase train\n",
      "PHASE train Loss: 0.0077 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.980     0.987      4528\n",
      "           1      0.984     0.996     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0453 Acc: 0.9885\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0022 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.993     0.993      4528\n",
      "           1      0.994     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0217 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.991      4528\n",
      "           1      0.994     0.991     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0269 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0019 Acc: 0.9996\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.988     0.991      4529\n",
      "           1      0.990     0.995     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9917\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.988     0.991      4528\n",
      "           1      0.990     0.995     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0294 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.984     0.989      4528\n",
      "           1      0.986     0.995     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0312 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0122 Acc: 0.9957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.976     0.976      4529\n",
      "           1      0.980     0.979     0.979      5399\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.977     0.978     0.977      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.0782 Acc: 0.9776\n",
      "Phase train\n",
      "PHASE train Loss: 0.0107 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.986     0.988      4528\n",
      "           1      0.989     0.991     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0376 Acc: 0.9888\n",
      "Phase train\n",
      "PHASE train Loss: 0.0067 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.992     0.988      4529\n",
      "           1      0.993     0.987     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0376 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0056 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.995     0.995      4528\n",
      "           1      0.996     0.996     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0189 Acc: 0.9954\n",
      "Phase train\n",
      "PHASE train Loss: 0.0043 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.994     0.995      4529\n",
      "           1      0.995     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0205 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0050 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.992      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0288 Acc: 0.9930\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0028 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.995     0.990      4528\n",
      "           1      0.996     0.987     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0335 Acc: 0.9909\n",
      "Phase train\n",
      "PHASE train Loss: 0.0029 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.992     0.993      4528\n",
      "           1      0.993     0.995     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0263 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.995     0.992      4529\n",
      "           1      0.996     0.991     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.992     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0229 Acc: 0.9927\n",
      "Phase train\n",
      "PHASE train Loss: 0.0037 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0239 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.996     0.990      4529\n",
      "           1      0.997     0.987     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0350 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0085 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.993      4529\n",
      "           1      0.994     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0216 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0041 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0231 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.995     0.991      4529\n",
      "           1      0.996     0.989     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0329 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.992     0.994      4529\n",
      "           1      0.994     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0202 Acc: 0.9944\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0038 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.996     0.986      4528\n",
      "           1      0.997     0.980     0.988      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.987      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0441 Acc: 0.9875\n",
      "Phase train\n",
      "PHASE train Loss: 0.0064 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.983     0.984      4529\n",
      "           1      0.985     0.988     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0493 Acc: 0.9853\n",
      "Phase train\n",
      "PHASE train Loss: 0.0039 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.993      4529\n",
      "           1      0.996     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0228 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.997     0.993      4529\n",
      "           1      0.998     0.990     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0256 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.990     0.987      4529\n",
      "           1      0.992     0.986     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0425 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0100 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.996     0.992      4529\n",
      "           1      0.997     0.990     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0253 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0034 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.993     0.994      4529\n",
      "           1      0.994     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0178 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.992      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0339 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.992     0.993      4528\n",
      "           1      0.994     0.995     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0218 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0019 Acc: 0.9996\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.992     0.994      4529\n",
      "           1      0.994     0.997     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0182 Acc: 0.9950\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0018 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.993     0.994      4529\n",
      "           1      0.994     0.996     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0197 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0021 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.991     0.993      4528\n",
      "           1      0.992     0.996     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0186 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0035 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.990     0.988      4529\n",
      "           1      0.991     0.989     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0371 Acc: 0.9894\n",
      "Phase train\n",
      "PHASE train Loss: 0.0060 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.993     0.993     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9926\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.992     0.992      4529\n",
      "           1      0.993     0.993     0.993      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0263 Acc: 0.9922\n",
      "Phase train\n",
      "PHASE train Loss: 0.0089 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.992     0.991      4528\n",
      "           1      0.993     0.991     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0333 Acc: 0.9917\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.968     0.979      4529\n",
      "           1      0.974     0.991     0.982      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.980     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0927 Acc: 0.9808\n",
      "Phase train\n",
      "PHASE train Loss: 0.0067 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.997     0.991      4529\n",
      "           1      0.997     0.987     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0278 Acc: 0.9913\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0223 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0233 Acc: 0.9934\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loaders = dict({'train': train_loader, 'val': val_loader})\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    bestmodel = train_valid_model (model,loaders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0062093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'resnet50best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe565062",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"resnet50\", pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a36f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ac1608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1709f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28fee4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "9928\n",
      "Test Loss: 0.0177 Acc: 0.9942\n",
      "4495  /  4528\n",
      "5375  /  5400\n"
     ]
    }
   ],
   "source": [
    "y_test, y_prob, y_pred= test_best_model (model, test_loader, a_device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f38492ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60ca5c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_prob[:,1])\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c9138a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curves and AUC\n",
    "plt.plot(fpr,tpr ,marker='.', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Resnet50 Fine-Tuning')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Resnet50 Fine-Tuning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4816685",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1590b9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941579371474617\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22445cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fbec970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946336047372316\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
