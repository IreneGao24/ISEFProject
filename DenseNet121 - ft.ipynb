{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9def3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import openslide\n",
    "from skimage.color import rgb2hsv\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import pathlib\n",
    "import tables\n",
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import kl_div, softmax, log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d43758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_img', 'test_label', 'train_img', 'train_label', 'val_img', 'val_label']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_path = '/home/irene/Downloads/luadlusc.hdf5'\n",
    "file = h5py.File(hdf5_path, \"r\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff03994",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean,rgb_std = (0.485, 0.456, 0.406),(0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bb0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, h5_path, set_name, transform = None):\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset = None\n",
    "        self.transform = transform\n",
    "        self.file_path  = h5_path\n",
    "        self.set = set_name\n",
    "        \n",
    "        str_name = self.set + \"_img\"\n",
    "        \n",
    "        file = h5py.File(h5_path, \"r\")\n",
    "        self.dataset_len = len(file[str_name])\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(rgb_mean,rgb_std)\n",
    "            ])\n",
    "        \n",
    "    def __getitem__(self, index): #to enable indexing\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.imgs = h5py.File(self.file_path, 'r')[self.set + \"_img\"]\n",
    "            self.labels = h5py.File(self.file_path, 'r')[self.set + \"_label\"]\n",
    "            \n",
    "            cur_img = self.imgs[index]\n",
    "            PIL_image = Image.fromarray(np.uint8(cur_img)).convert('RGB')#3 channels don't need alpha channel network input\n",
    "            image = self.transform(PIL_image)\n",
    "            label = self.labels[index].astype('float32')\n",
    "            \n",
    "            \n",
    "        return (image,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f00c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "train_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"train\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "val_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"val\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "test_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"test\"), batch_size=8,shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b47453a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"densenet121\", pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, out_dim)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train_valid_model (net,loaders,max_epochs = 20):\n",
    "    best_acc = 0.0 \n",
    "    for epoch in range (max_epochs):\n",
    "        for phase in ['train','val']:\n",
    "            iterator = iter(loaders[phase])\n",
    "            total_step = len(loaders[phase])\n",
    "            print('Phase {}'.format(phase))\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "            predictions_all = []\n",
    "            label_all = []\n",
    "            probs_all = []\n",
    "            for step in range(total_step-1): #iterate each batch\n",
    "                images,labels = next(iterator) # CUDA computation\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = net(images)\n",
    "                loss = criterion(output,labels)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(output, dim=1) # probabilities\n",
    "                \n",
    "                running_loss +=loss.item()\n",
    "                _, preds = torch.max(output.data,1)\n",
    "                \n",
    "                running_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                if len(predictions_all) == 0:\n",
    "                    predictions_all = preds.detach().cpu().numpy()\n",
    "                    label_all = labels.detach().cpu().numpy()\n",
    "                    probs_all = probs.detach().cpu().numpy()\n",
    "                else:\n",
    "                    predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                    probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "                    label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "                    \n",
    "            phase_loss = running_loss / len(loaders[phase])\n",
    "            phase_acc = running_correct/len(label_all.flatten())\n",
    "            if phase == 'val':\n",
    "                y_true = label_all.flatten()\n",
    "                y_pred = predictions_all.flatten()\n",
    "                print(\"validating...\")\n",
    "                print(len(y_true))\n",
    "                print(len(y_pred))\n",
    "                print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "            if phase == 'val' and phase_acc > best_acc:\n",
    "                \n",
    "                best_acc = phase_acc\n",
    "                import copy \n",
    "                \n",
    "                best_model_state_dict = copy.deepcopy(net.state_dict())\n",
    "                torch.save(best_model_state_dict,'densenet121best_model.pth')\n",
    "                \n",
    "            print('PHASE {} Loss: {:.4f} Acc: {:.4f}'.format(phase, phase_loss, phase_acc))\n",
    "    net.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    return net \n",
    "            \n",
    "       \n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72632936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model (net, test_loader, a_device = None):\n",
    "    iterator = iter(test_loader)\n",
    "    total_step = len(test_loader)\n",
    "    \n",
    "    print(total_step)\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        total_0,total_1 = 0,0\n",
    "        hit_0 = 0\n",
    "        hit_1 = 0\n",
    "        label_all = []\n",
    "        probs_all = []\n",
    "        predictions_all = []\n",
    "        for step in range(total_step-1):\n",
    "            images,labels = next(iterator)\n",
    "            images.to(a_device)\n",
    "            labels.to(a_device)\n",
    "            total_0 += labels.tolist().count(0)\n",
    "            total_1 += labels.tolist().count(1)\n",
    "            print(labels.shape)\n",
    "            images = images.to(a_device)\n",
    "            labels = labels.to(device=a_device, dtype=torch.int64)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            output = net(images)\n",
    "            loss = criterion(output,labels)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "            _, preds = torch.max(output.data,1)\n",
    "            \n",
    "            equals = preds == labels.view(*preds.shape)\n",
    "            if(len(label_all) ==0):\n",
    "                predictions_all = preds.detach().cpu().numpy()\n",
    "                label_all = labels.detach().cpu().numpy()\n",
    "                probs_all = probs.detach().cpu().numpy()\n",
    "            else:\n",
    "                predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "                probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "\n",
    "            all_hits = equals.view(equals.shape[0]).tolist() \n",
    "            all_corrects = labels[all_hits]\n",
    "            \n",
    "            hit_0 += all_corrects.tolist().count(0)\n",
    "            hit_1 += all_corrects.tolist().count(1)\n",
    " \n",
    "        \n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "        print(len(label_all.flatten()))\n",
    "        label_all = label_all.flatten()\n",
    "        predictions_all = predictions_all.flatten()\n",
    "        phase_loss = running_loss / len(test_loader)\n",
    "        phase_acc = running_corrects/len(label_all.flatten())\n",
    "        print('Test Loss: {:.4f} Acc: {:.4f}'.format(phase_loss, phase_acc))\n",
    "        \n",
    "        print(hit_0, ' / ',total_0)\n",
    "        print(hit_1, ' / ',total_1)\n",
    "                \n",
    "            \n",
    "    return label_all, probs_all, predictions_all #add this later\n",
    "                \n",
    "        #y_test --> label, y_score --> probs all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eeb8241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.4677 Acc: 0.7766\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.870     0.911     0.890      4528\n",
      "           1      0.923     0.886     0.904      5400\n",
      "\n",
      "    accuracy                          0.898      9928\n",
      "   macro avg      0.897     0.899     0.897      9928\n",
      "weighted avg      0.899     0.898     0.898      9928\n",
      "\n",
      "PHASE val Loss: 0.3405 Acc: 0.8978\n",
      "Phase train\n",
      "PHASE train Loss: 0.2813 Acc: 0.8778\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.835     0.926     0.878      4529\n",
      "           1      0.932     0.846     0.887      5399\n",
      "\n",
      "    accuracy                          0.883      9928\n",
      "   macro avg      0.884     0.886     0.883      9928\n",
      "weighted avg      0.888     0.883     0.883      9928\n",
      "\n",
      "PHASE val Loss: 3.6522 Acc: 0.8830\n",
      "Phase train\n",
      "PHASE train Loss: 0.1983 Acc: 0.9176\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.920     0.965     0.942      4528\n",
      "           1      0.969     0.930     0.949      5400\n",
      "\n",
      "    accuracy                          0.946      9928\n",
      "   macro avg      0.945     0.948     0.946      9928\n",
      "weighted avg      0.947     0.946     0.946      9928\n",
      "\n",
      "PHASE val Loss: 0.7260 Acc: 0.9460\n",
      "Phase train\n",
      "PHASE train Loss: 0.1348 Acc: 0.9483\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.969     0.956      4529\n",
      "           1      0.973     0.952     0.962      5399\n",
      "\n",
      "    accuracy                          0.959      9928\n",
      "   macro avg      0.958     0.960     0.959      9928\n",
      "weighted avg      0.960     0.959     0.959      9928\n",
      "\n",
      "PHASE val Loss: 0.4702 Acc: 0.9594\n",
      "Phase train\n",
      "PHASE train Loss: 0.1091 Acc: 0.9574\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.925     0.976     0.950      4529\n",
      "           1      0.979     0.934     0.956      5399\n",
      "\n",
      "    accuracy                          0.953      9928\n",
      "   macro avg      0.952     0.955     0.953      9928\n",
      "weighted avg      0.954     0.953     0.953      9928\n",
      "\n",
      "PHASE val Loss: 0.9444 Acc: 0.9531\n",
      "Phase train\n",
      "PHASE train Loss: 0.0789 Acc: 0.9711\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.988     0.962      4529\n",
      "           1      0.989     0.946     0.967      5399\n",
      "\n",
      "    accuracy                          0.965      9928\n",
      "   macro avg      0.964     0.967     0.965      9928\n",
      "weighted avg      0.966     0.965     0.965      9928\n",
      "\n",
      "PHASE val Loss: 0.7360 Acc: 0.9647\n",
      "Phase train\n",
      "PHASE train Loss: 0.0697 Acc: 0.9747\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.921     0.970     0.945      4529\n",
      "           1      0.974     0.930     0.951      5399\n",
      "\n",
      "    accuracy                          0.948      9928\n",
      "   macro avg      0.947     0.950     0.948      9928\n",
      "weighted avg      0.950     0.948     0.949      9928\n",
      "\n",
      "PHASE val Loss: 1.4392 Acc: 0.9484\n",
      "Phase train\n",
      "PHASE train Loss: 0.0616 Acc: 0.9771\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.966     0.953      4529\n",
      "           1      0.971     0.949     0.960      5399\n",
      "\n",
      "    accuracy                          0.957      9928\n",
      "   macro avg      0.956     0.958     0.957      9928\n",
      "weighted avg      0.957     0.957     0.957      9928\n",
      "\n",
      "PHASE val Loss: 0.5790 Acc: 0.9569\n",
      "Phase train\n",
      "PHASE train Loss: 0.0509 Acc: 0.9821\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.936     0.983     0.959      4528\n",
      "           1      0.985     0.943     0.964      5400\n",
      "\n",
      "    accuracy                          0.962      9928\n",
      "   macro avg      0.961     0.963     0.961      9928\n",
      "weighted avg      0.963     0.962     0.962      9928\n",
      "\n",
      "PHASE val Loss: 1.6425 Acc: 0.9616\n",
      "Phase train\n",
      "PHASE train Loss: 0.0405 Acc: 0.9853\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.925     0.991     0.957      4528\n",
      "           1      0.992     0.933     0.962      5400\n",
      "\n",
      "    accuracy                          0.960      9928\n",
      "   macro avg      0.959     0.962     0.959      9928\n",
      "weighted avg      0.962     0.960     0.960      9928\n",
      "\n",
      "PHASE val Loss: 1.8231 Acc: 0.9595\n",
      "Phase train\n",
      "PHASE train Loss: 0.0362 Acc: 0.9866\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.979     0.973      4529\n",
      "           1      0.982     0.971     0.977      5399\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.974     0.975     0.975      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.2007 Acc: 0.9749\n",
      "Phase train\n",
      "PHASE train Loss: 0.0328 Acc: 0.9887\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.929     0.995     0.961      4529\n",
      "           1      0.995     0.936     0.965      5399\n",
      "\n",
      "    accuracy                          0.963      9928\n",
      "   macro avg      0.962     0.965     0.963      9928\n",
      "weighted avg      0.965     0.963     0.963      9928\n",
      "\n",
      "PHASE val Loss: 1.4773 Acc: 0.9629\n",
      "Phase train\n",
      "PHASE train Loss: 0.0286 Acc: 0.9905\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.964     0.980      4529\n",
      "           1      0.971     0.996     0.984      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.983     0.980     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0830 Acc: 0.9819\n",
      "Phase train\n",
      "PHASE train Loss: 0.0253 Acc: 0.9918\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.993     0.984      4529\n",
      "           1      0.994     0.979     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.1443 Acc: 0.9852\n",
      "Phase train\n",
      "PHASE train Loss: 0.0235 Acc: 0.9921\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.957     0.988     0.972      4529\n",
      "           1      0.989     0.963     0.976      5399\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.973     0.975     0.974      9928\n",
      "weighted avg      0.974     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 0.5281 Acc: 0.9740\n",
      "Phase train\n",
      "PHASE train Loss: 0.0204 Acc: 0.9935\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.966     0.975      4529\n",
      "           1      0.972     0.988     0.980      5399\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.978     0.977     0.978      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.2085 Acc: 0.9777\n",
      "Phase train\n",
      "PHASE train Loss: 0.0225 Acc: 0.9925\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.958     0.994     0.975      4528\n",
      "           1      0.994     0.963     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.976     0.978     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.4612 Acc: 0.9771\n",
      "Phase train\n",
      "PHASE train Loss: 0.0176 Acc: 0.9943\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.983     0.982      4528\n",
      "           1      0.986     0.984     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0792 Acc: 0.9840\n",
      "Phase train\n",
      "PHASE train Loss: 0.0209 Acc: 0.9922\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.948     0.964      4529\n",
      "           1      0.957     0.985     0.971      5399\n",
      "\n",
      "    accuracy                          0.968      9928\n",
      "   macro avg      0.969     0.966     0.968      9928\n",
      "weighted avg      0.968     0.968     0.968      9928\n",
      "\n",
      "PHASE val Loss: 1.1063 Acc: 0.9679\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0194 Acc: 0.9934\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.978     0.975      4528\n",
      "           1      0.981     0.976     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.977     0.977     0.977      9928\n",
      "weighted avg      0.977     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.2290 Acc: 0.9769\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0229 Acc: 0.9923\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.987     0.984      4529\n",
      "           1      0.989     0.984     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0727 Acc: 0.9851\n",
      "Phase train\n",
      "PHASE train Loss: 0.0205 Acc: 0.9931\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.973     0.982      4529\n",
      "           1      0.978     0.993     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.983     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.1799 Acc: 0.9840\n",
      "Phase train\n",
      "PHASE train Loss: 0.0185 Acc: 0.9940\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.961     0.974      4529\n",
      "           1      0.968     0.989     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.977     0.975     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.3808 Acc: 0.9762\n",
      "Phase train\n",
      "PHASE train Loss: 0.0186 Acc: 0.9935\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.972     0.983      4528\n",
      "           1      0.977     0.995     0.986      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.983     0.984      9928\n",
      "weighted avg      0.985     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0646 Acc: 0.9844\n",
      "Phase train\n",
      "PHASE train Loss: 0.0161 Acc: 0.9946\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.992     0.988      4529\n",
      "           1      0.993     0.986     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0621 Acc: 0.9887\n",
      "Phase train\n",
      "PHASE train Loss: 0.0180 Acc: 0.9938\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.992     0.981      4529\n",
      "           1      0.993     0.974     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0952 Acc: 0.9822\n",
      "Phase train\n",
      "PHASE train Loss: 0.0139 Acc: 0.9952\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.984     0.987      4528\n",
      "           1      0.987     0.992     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0487 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0135 Acc: 0.9956\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.950     0.992     0.970      4529\n",
      "           1      0.993     0.956     0.974      5399\n",
      "\n",
      "    accuracy                          0.972      9928\n",
      "   macro avg      0.971     0.974     0.972      9928\n",
      "weighted avg      0.973     0.972     0.972      9928\n",
      "\n",
      "PHASE val Loss: 0.9219 Acc: 0.9723\n",
      "Phase train\n",
      "PHASE train Loss: 0.0156 Acc: 0.9945\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.928     0.960      4529\n",
      "           1      0.942     0.995     0.968      5399\n",
      "\n",
      "    accuracy                          0.964      9928\n",
      "   macro avg      0.968     0.961     0.964      9928\n",
      "weighted avg      0.966     0.964     0.964      9928\n",
      "\n",
      "PHASE val Loss: 0.9542 Acc: 0.9644\n",
      "Phase train\n",
      "PHASE train Loss: 0.0161 Acc: 0.9949\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.963     0.974      4528\n",
      "           1      0.970     0.988     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.978     0.976     0.977      9928\n",
      "weighted avg      0.977     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.3570 Acc: 0.9767\n",
      "Phase train\n",
      "PHASE train Loss: 0.0119 Acc: 0.9960\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.968     0.979      4528\n",
      "           1      0.974     0.992     0.983      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.980     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.1669 Acc: 0.9810\n",
      "Phase train\n",
      "PHASE train Loss: 0.0106 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.989     0.981      4528\n",
      "           1      0.991     0.976     0.983      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.982     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.3538 Acc: 0.9822\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.959     0.993     0.975      4529\n",
      "           1      0.994     0.964     0.979      5399\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.976     0.978     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.9210 Acc: 0.9771\n",
      "Phase train\n",
      "PHASE train Loss: 0.0083 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.994     0.984      4529\n",
      "           1      0.995     0.977     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.984     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.3049 Acc: 0.9849\n",
      "Phase train\n",
      "PHASE train Loss: 0.0100 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.984     0.986      4529\n",
      "           1      0.987     0.989     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0906 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0106 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.996     0.981      4529\n",
      "           1      0.996     0.972     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.984     0.982      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.2051 Acc: 0.9826\n",
      "Phase train\n",
      "PHASE train Loss: 0.0085 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.953     0.995     0.974      4528\n",
      "           1      0.996     0.959     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.974     0.977     0.975      9928\n",
      "weighted avg      0.976     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.6466 Acc: 0.9753\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.983     0.984      4528\n",
      "           1      0.985     0.988     0.987      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0956 Acc: 0.9854\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0084 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.930     0.962      4528\n",
      "           1      0.944     0.997     0.970      5400\n",
      "\n",
      "    accuracy                          0.966      9928\n",
      "   macro avg      0.970     0.963     0.966      9928\n",
      "weighted avg      0.968     0.966     0.966      9928\n",
      "\n",
      "PHASE val Loss: 2.3572 Acc: 0.9661\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.935     0.963      4529\n",
      "           1      0.948     0.995     0.971      5399\n",
      "\n",
      "    accuracy                          0.968      9928\n",
      "   macro avg      0.971     0.965     0.967      9928\n",
      "weighted avg      0.969     0.968     0.967      9928\n",
      "\n",
      "PHASE val Loss: 2.2201 Acc: 0.9676\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0159 Acc: 0.9948\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.965     0.978      4529\n",
      "           1      0.971     0.993     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.3519 Acc: 0.9801\n",
      "Phase train\n",
      "PHASE train Loss: 0.0134 Acc: 0.9952\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.952     0.973      4528\n",
      "           1      0.961     0.996     0.978      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.978     0.974     0.976      9928\n",
      "weighted avg      0.977     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.8071 Acc: 0.9761\n",
      "Phase train\n",
      "PHASE train Loss: 0.0145 Acc: 0.9952\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.988     0.986      4529\n",
      "           1      0.990     0.986     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0674 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0128 Acc: 0.9959\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.960     0.991     0.975      4528\n",
      "           1      0.992     0.965     0.978      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.976     0.978     0.977      9928\n",
      "weighted avg      0.977     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.8204 Acc: 0.9768\n",
      "Phase train\n",
      "PHASE train Loss: 0.0114 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.972     0.981      4529\n",
      "           1      0.977     0.992     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.984     0.982     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.1874 Acc: 0.9830\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.973     0.978      4529\n",
      "           1      0.978     0.986     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.980     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.2783 Acc: 0.9803\n",
      "Phase train\n",
      "PHASE train Loss: 0.0096 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.962     0.978      4529\n",
      "           1      0.969     0.995     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.2385 Acc: 0.9801\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.979     0.984      4528\n",
      "           1      0.983     0.991     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.985     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1088 Acc: 0.9858\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.977     0.980      4529\n",
      "           1      0.981     0.986     0.984      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.982     0.982     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.3690 Acc: 0.9821\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.996     0.981      4528\n",
      "           1      0.996     0.971     0.983      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.4674 Acc: 0.9821\n",
      "Phase train\n",
      "PHASE train Loss: 0.0075 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.956     0.975      4528\n",
      "           1      0.964     0.997     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.980     0.976     0.978      9928\n",
      "weighted avg      0.979     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.2281 Acc: 0.9779\n",
      "Phase train\n",
      "PHASE train Loss: 0.0091 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.995     0.967      4529\n",
      "           1      0.996     0.948     0.971      5399\n",
      "\n",
      "    accuracy                          0.969      9928\n",
      "   macro avg      0.968     0.971     0.969      9928\n",
      "weighted avg      0.971     0.969     0.969      9928\n",
      "\n",
      "PHASE val Loss: 1.1917 Acc: 0.9694\n",
      "Phase train\n",
      "PHASE train Loss: 0.0090 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.961     0.977      4529\n",
      "           1      0.968     0.995     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.981     0.978     0.979      9928\n",
      "weighted avg      0.980     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.6509 Acc: 0.9793\n",
      "Phase train\n",
      "PHASE train Loss: 0.0098 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.961     0.992     0.976      4528\n",
      "           1      0.993     0.967     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.977     0.979     0.978      9928\n",
      "weighted avg      0.979     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.7100 Acc: 0.9781\n",
      "Phase train\n",
      "PHASE train Loss: 0.0092 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.954     0.974      4528\n",
      "           1      0.963     0.996     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.979     0.975     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.4497 Acc: 0.9770\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.994     0.984      4529\n",
      "           1      0.995     0.978     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.984     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.3105 Acc: 0.9852\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.989     0.983      4528\n",
      "           1      0.990     0.980     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.2415 Acc: 0.9842\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0092 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.976     0.984      4529\n",
      "           1      0.980     0.994     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.985     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.2371 Acc: 0.9858\n",
      "Phase train\n",
      "PHASE train Loss: 0.0058 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.951     0.973      4529\n",
      "           1      0.960     0.997     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.978     0.974     0.976      9928\n",
      "weighted avg      0.977     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.7762 Acc: 0.9760\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.957     0.975      4528\n",
      "           1      0.965     0.995     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.979     0.976     0.977      9928\n",
      "weighted avg      0.978     0.978     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.9344 Acc: 0.9775\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0140 Acc: 0.9950\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.955     0.995     0.974      4528\n",
      "           1      0.995     0.960     0.978      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.975     0.978     0.976      9928\n",
      "weighted avg      0.977     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.8141 Acc: 0.9760\n",
      "Phase train\n",
      "PHASE train Loss: 0.0102 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.990     0.982      4528\n",
      "           1      0.992     0.978     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.984     0.983      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.2439 Acc: 0.9836\n",
      "Phase train\n",
      "PHASE train Loss: 0.0100 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.996     0.986      4528\n",
      "           1      0.996     0.981     0.988      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.987      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0809 Acc: 0.9875\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.965     0.975      4528\n",
      "           1      0.971     0.988     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.978     0.977     0.978      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.1489 Acc: 0.9777\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.961     0.978      4529\n",
      "           1      0.968     0.996     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.982     0.979     0.980      9928\n",
      "weighted avg      0.981     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.4121 Acc: 0.9803\n",
      "Phase train\n",
      "PHASE train Loss: 0.0140 Acc: 0.9958\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.961     0.988     0.975      4529\n",
      "           1      0.990     0.966     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.976     0.977     0.976      9928\n",
      "weighted avg      0.977     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.2481 Acc: 0.9764\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.958     0.994     0.975      4528\n",
      "           1      0.995     0.963     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.976     0.978     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.4216 Acc: 0.9771\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.993     0.985      4529\n",
      "           1      0.994     0.981     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.1158 Acc: 0.9866\n",
      "Phase train\n",
      "PHASE train Loss: 0.0108 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.994     0.981      4529\n",
      "           1      0.995     0.972     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.2993 Acc: 0.9821\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.980     0.986      4529\n",
      "           1      0.983     0.993     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0726 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.979     0.985      4528\n",
      "           1      0.983     0.992     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0817 Acc: 0.9861\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.954     0.985     0.969      4529\n",
      "           1      0.987     0.960     0.973      5399\n",
      "\n",
      "    accuracy                          0.971      9928\n",
      "   macro avg      0.971     0.973     0.971      9928\n",
      "weighted avg      0.972     0.971     0.972      9928\n",
      "\n",
      "PHASE val Loss: 1.0536 Acc: 0.9715\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.968     0.978      4528\n",
      "           1      0.974     0.991     0.982      5400\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.981     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.1934 Acc: 0.9805\n",
      "Phase train\n",
      "PHASE train Loss: 0.0105 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.949     0.968      4529\n",
      "           1      0.959     0.989     0.974      5399\n",
      "\n",
      "    accuracy                          0.971      9928\n",
      "   macro avg      0.973     0.969     0.971      9928\n",
      "weighted avg      0.971     0.971     0.971      9928\n",
      "\n",
      "PHASE val Loss: 1.0747 Acc: 0.9710\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.951     0.972      4529\n",
      "           1      0.961     0.995     0.977      5399\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.977     0.973     0.975      9928\n",
      "weighted avg      0.976     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 1.2108 Acc: 0.9749\n",
      "Phase train\n",
      "PHASE train Loss: 0.0077 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.949     0.971      4529\n",
      "           1      0.959     0.995     0.977      5399\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.977     0.972     0.974      9928\n",
      "weighted avg      0.975     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 1.0584 Acc: 0.9743\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0080 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.961     0.972      4529\n",
      "           1      0.968     0.985     0.977      5399\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.975     0.973     0.974      9928\n",
      "weighted avg      0.975     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 1.0493 Acc: 0.9744\n",
      "Phase train\n",
      "PHASE train Loss: 0.0084 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.979     0.984      4528\n",
      "           1      0.983     0.991     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.985     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1245 Acc: 0.9859\n",
      "Phase train\n",
      "PHASE train Loss: 0.0068 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.984     0.985      4529\n",
      "           1      0.987     0.988     0.988      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1969 Acc: 0.9864\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.947     0.971      4528\n",
      "           1      0.957     0.997     0.977      5400\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.977     0.972     0.974      9928\n",
      "weighted avg      0.975     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 0.5170 Acc: 0.9742\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.990     0.984      4529\n",
      "           1      0.991     0.982     0.987      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.1476 Acc: 0.9854\n",
      "Phase train\n",
      "PHASE train Loss: 0.0102 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.985     0.985      4528\n",
      "           1      0.988     0.987     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1625 Acc: 0.9861\n",
      "Phase train\n",
      "PHASE train Loss: 0.0105 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.991     0.979      4528\n",
      "           1      0.992     0.971     0.982      5400\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.979     0.981     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.2906 Acc: 0.9802\n",
      "Phase train\n",
      "PHASE train Loss: 0.0128 Acc: 0.9960\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.986     0.989      4528\n",
      "           1      0.989     0.994     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0618 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.994     0.981      4529\n",
      "           1      0.995     0.973     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.984     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.5009 Acc: 0.9827\n",
      "Phase train\n",
      "PHASE train Loss: 0.0094 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.948     0.984     0.966      4528\n",
      "           1      0.986     0.955     0.970      5400\n",
      "\n",
      "    accuracy                          0.968      9928\n",
      "   macro avg      0.967     0.970     0.968      9928\n",
      "weighted avg      0.969     0.968     0.968      9928\n",
      "\n",
      "PHASE val Loss: 2.4886 Acc: 0.9683\n",
      "Phase train\n",
      "PHASE train Loss: 0.0092 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.915     0.996     0.954      4528\n",
      "           1      0.996     0.923     0.958      5400\n",
      "\n",
      "    accuracy                          0.956      9928\n",
      "   macro avg      0.956     0.959     0.956      9928\n",
      "weighted avg      0.959     0.956     0.956      9928\n",
      "\n",
      "PHASE val Loss: 8.8254 Acc: 0.9562\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.987     0.978      4529\n",
      "           1      0.989     0.973     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.979     0.980     0.979      9928\n",
      "weighted avg      0.980     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.5488 Acc: 0.9794\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.994     0.987      4529\n",
      "           1      0.995     0.983     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.1000 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.981     0.988      4529\n",
      "           1      0.984     0.996     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0573 Acc: 0.9887\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.991     0.989      4529\n",
      "           1      0.993     0.988     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.1069 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0067 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.961     0.995     0.978      4528\n",
      "           1      0.996     0.966     0.981      5400\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.978     0.981     0.979      9928\n",
      "weighted avg      0.980     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.7672 Acc: 0.9794\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.963     0.994     0.978      4529\n",
      "           1      0.995     0.968     0.981      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.979     0.981     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.5299 Acc: 0.9799\n",
      "Phase train\n",
      "PHASE train Loss: 0.0077 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.997     0.981      4529\n",
      "           1      0.997     0.971     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.984     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.4751 Acc: 0.9827\n",
      "Phase train\n",
      "PHASE train Loss: 0.0059 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.919     0.995     0.956      4529\n",
      "           1      0.996     0.927     0.960      5399\n",
      "\n",
      "    accuracy                          0.958      9928\n",
      "   macro avg      0.957     0.961     0.958      9928\n",
      "weighted avg      0.961     0.958     0.958      9928\n",
      "\n",
      "PHASE val Loss: 5.5868 Acc: 0.9579\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0068 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.987     0.979      4528\n",
      "           1      0.989     0.977     0.983      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.981     0.982     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 1.2588 Acc: 0.9812\n",
      "Phase train\n",
      "PHASE train Loss: 0.0058 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.998     0.954      4529\n",
      "           1      0.998     0.921     0.958      5399\n",
      "\n",
      "    accuracy                          0.956      9928\n",
      "   macro avg      0.956     0.959     0.956      9928\n",
      "weighted avg      0.959     0.956     0.956      9928\n",
      "\n",
      "PHASE val Loss: 6.4818 Acc: 0.9558\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.955     0.993     0.974      4529\n",
      "           1      0.994     0.961     0.977      5399\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.974     0.977     0.975      9928\n",
      "weighted avg      0.976     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 2.4521 Acc: 0.9754\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.993     0.980      4529\n",
      "           1      0.994     0.972     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.981     0.982     0.981      9928\n",
      "weighted avg      0.982     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 1.0188 Acc: 0.9814\n",
      "Phase train\n",
      "PHASE train Loss: 0.0038 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.961     0.979      4529\n",
      "           1      0.969     0.997     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.979     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.3912 Acc: 0.9808\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.995     0.982      4529\n",
      "           1      0.996     0.974     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.5902 Acc: 0.9837\n",
      "Phase train\n",
      "PHASE train Loss: 0.0075 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.954     0.975      4528\n",
      "           1      0.963     0.997     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.979     0.975     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.6254 Acc: 0.9772\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.987     0.989      4529\n",
      "           1      0.989     0.993     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0741 Acc: 0.9899\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.990     0.984      4528\n",
      "           1      0.992     0.982     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.4055 Acc: 0.9856\n",
      "Phase train\n",
      "PHASE train Loss: 0.0107 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.932     0.996     0.963      4528\n",
      "           1      0.996     0.939     0.967      5400\n",
      "\n",
      "    accuracy                          0.965      9928\n",
      "   macro avg      0.964     0.967     0.965      9928\n",
      "weighted avg      0.967     0.965     0.965      9928\n",
      "\n",
      "PHASE val Loss: 3.0599 Acc: 0.9649\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.949     0.996     0.972      4529\n",
      "           1      0.996     0.955     0.975      5399\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.973     0.975     0.974      9928\n",
      "weighted avg      0.975     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 3.1082 Acc: 0.9737\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.996     0.982      4529\n",
      "           1      0.997     0.973     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.9403 Acc: 0.9837\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.994     0.986      4529\n",
      "           1      0.995     0.981     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.988     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.5669 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.971     0.974      4528\n",
      "           1      0.976     0.980     0.978      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.976     0.976     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.5828 Acc: 0.9760\n",
      "Phase train\n",
      "PHASE train Loss: 0.0075 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.996     0.987      4528\n",
      "           1      0.997     0.981     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.3433 Acc: 0.9882\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.979     0.977      4529\n",
      "           1      0.982     0.979     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.979     0.979     0.979      9928\n",
      "weighted avg      0.979     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.7977 Acc: 0.9790\n",
      "Phase train\n",
      "PHASE train Loss: 0.0065 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.974     0.984      4529\n",
      "           1      0.979     0.996     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.987     0.985     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1569 Acc: 0.9859\n",
      "Phase train\n",
      "PHASE train Loss: 0.0064 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.993     0.982      4528\n",
      "           1      0.994     0.975     0.985      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.984     0.983      9928\n",
      "weighted avg      0.984     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.6072 Acc: 0.9834\n",
      "Phase train\n",
      "PHASE train Loss: 0.0084 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.978     0.983      4528\n",
      "           1      0.982     0.990     0.986      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.984     0.984      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.1040 Acc: 0.9846\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0051 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.993     0.984      4528\n",
      "           1      0.994     0.980     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.985     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.3363 Acc: 0.9856\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.943     0.994     0.968      4528\n",
      "           1      0.994     0.950     0.971      5400\n",
      "\n",
      "    accuracy                          0.970      9928\n",
      "   macro avg      0.969     0.972     0.970      9928\n",
      "weighted avg      0.971     0.970     0.970      9928\n",
      "\n",
      "PHASE val Loss: 2.5051 Acc: 0.9697\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.991     0.978      4529\n",
      "           1      0.992     0.971     0.981      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.979     0.981     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 1.1736 Acc: 0.9799\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.992     0.980      4529\n",
      "           1      0.993     0.973     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.980     0.982     0.981      9928\n",
      "weighted avg      0.982     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.7149 Acc: 0.9813\n",
      "Phase train\n",
      "PHASE train Loss: 0.0065 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.993     0.984      4528\n",
      "           1      0.994     0.978     0.986      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.3335 Acc: 0.9852\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.982     0.980      4528\n",
      "           1      0.985     0.982     0.984      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.982     0.982     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.2924 Acc: 0.9822\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0115 Acc: 0.9958\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.990     0.986      4528\n",
      "           1      0.992     0.985     0.988      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.987      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0994 Acc: 0.9875\n",
      "Phase train\n",
      "PHASE train Loss: 0.0091 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.985     0.986      4528\n",
      "           1      0.987     0.990     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.987     0.987      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.1045 Acc: 0.9875\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.938     0.966      4529\n",
      "           1      0.950     0.997     0.973      5399\n",
      "\n",
      "    accuracy                          0.970      9928\n",
      "   macro avg      0.973     0.967     0.969      9928\n",
      "weighted avg      0.971     0.970     0.970      9928\n",
      "\n",
      "PHASE val Loss: 1.1868 Acc: 0.9699\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.979     0.981      4528\n",
      "           1      0.982     0.986     0.984      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.982     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0962 Acc: 0.9828\n",
      "Phase train\n",
      "PHASE train Loss: 0.0068 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.997     0.962     0.979      4529\n",
      "           1      0.969     0.998     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.983     0.980     0.981      9928\n",
      "weighted avg      0.982     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.2451 Acc: 0.9815\n",
      "Phase train\n",
      "PHASE train Loss: 0.0083 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.966     0.980      4528\n",
      "           1      0.972     0.995     0.983      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.983     0.981     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.3680 Acc: 0.9818\n",
      "Phase train\n",
      "PHASE train Loss: 0.0050 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.992     0.991      4529\n",
      "           1      0.993     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0483 Acc: 0.9915\n",
      "Phase train\n",
      "PHASE train Loss: 0.0065 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.954     0.973      4529\n",
      "           1      0.962     0.995     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.978     0.974     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.4734 Acc: 0.9759\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.993     0.987      4529\n",
      "           1      0.994     0.983     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.1882 Acc: 0.9876\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.969     0.980      4528\n",
      "           1      0.974     0.994     0.984      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.983     0.981     0.982      9928\n",
      "weighted avg      0.983     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.3057 Acc: 0.9824\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.985     0.979      4528\n",
      "           1      0.987     0.977     0.982      5400\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.980     0.981     0.980      9928\n",
      "weighted avg      0.981     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.3326 Acc: 0.9805\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.978     0.978      4529\n",
      "           1      0.982     0.982     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.980     0.980     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.2234 Acc: 0.9801\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.994     0.990      4528\n",
      "           1      0.995     0.988     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0922 Acc: 0.9910\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0069 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.977     0.981      4528\n",
      "           1      0.981     0.988     0.984      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.982     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.1294 Acc: 0.9829\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.978     0.984      4529\n",
      "           1      0.981     0.992     0.987      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.986     0.985     0.985      9928\n",
      "weighted avg      0.986     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0746 Acc: 0.9855\n",
      "Phase train\n",
      "PHASE train Loss: 0.0029 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.968     0.998     0.983      4529\n",
      "           1      0.998     0.973     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.985     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.6127 Acc: 0.9842\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.996     0.980      4528\n",
      "           1      0.996     0.970     0.983      5400\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.7786 Acc: 0.9819\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.988     0.980      4529\n",
      "           1      0.990     0.976     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.982     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.7140 Acc: 0.9817\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.970     0.982      4529\n",
      "           1      0.975     0.995     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.982     0.983      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.1104 Acc: 0.9836\n",
      "Phase train\n",
      "PHASE train Loss: 0.0080 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.973     0.980      4529\n",
      "           1      0.977     0.989     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.982     0.981     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.1845 Acc: 0.9819\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0050 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.997     0.989      4529\n",
      "           1      0.997     0.984     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.991     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.1362 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.983     0.989      4529\n",
      "           1      0.986     0.995     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0643 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.993     0.981      4529\n",
      "           1      0.994     0.974     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.984     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.3127 Acc: 0.9829\n",
      "Phase train\n",
      "PHASE train Loss: 0.0059 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.964     0.975      4529\n",
      "           1      0.970     0.990     0.980      5399\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.979     0.977     0.978      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.3127 Acc: 0.9778\n",
      "Phase train\n",
      "PHASE train Loss: 0.0091 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.961     0.977      4529\n",
      "           1      0.968     0.995     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.978     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.3396 Acc: 0.9798\n",
      "Phase train\n",
      "PHASE train Loss: 0.0091 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.975     0.978      4529\n",
      "           1      0.979     0.984     0.981      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.980     0.979     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.4434 Acc: 0.9798\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.989     0.986      4528\n",
      "           1      0.990     0.986     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.1186 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.994     0.983      4529\n",
      "           1      0.995     0.976     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.4127 Acc: 0.9842\n",
      "Phase train\n",
      "PHASE train Loss: 0.0041 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.988     0.980      4529\n",
      "           1      0.990     0.976     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.982     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.3109 Acc: 0.9817\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.954     0.994     0.973      4528\n",
      "           1      0.994     0.960     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.974     0.977     0.975      9928\n",
      "weighted avg      0.976     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 1.5270 Acc: 0.9751\n",
      "Phase train\n",
      "PHASE train Loss: 0.0064 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.996     0.985      4529\n",
      "           1      0.996     0.979     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.3821 Acc: 0.9866\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.926     0.959      4529\n",
      "           1      0.941     0.995     0.968      5399\n",
      "\n",
      "    accuracy                          0.964      9928\n",
      "   macro avg      0.968     0.961     0.963      9928\n",
      "weighted avg      0.965     0.964     0.964      9928\n",
      "\n",
      "PHASE val Loss: 2.7780 Acc: 0.9636\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0057 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.975     0.984      4529\n",
      "           1      0.980     0.995     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.987     0.985     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0650 Acc: 0.9859\n",
      "Phase train\n",
      "PHASE train Loss: 0.0045 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.976     0.985      4528\n",
      "           1      0.980     0.995     0.988      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.987     0.986     0.986      9928\n",
      "weighted avg      0.987     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.1079 Acc: 0.9864\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.956     0.996     0.976      4529\n",
      "           1      0.997     0.962     0.979      5399\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.977     0.979     0.977      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.9990 Acc: 0.9775\n",
      "Phase train\n",
      "PHASE train Loss: 0.0033 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.977     0.987      4529\n",
      "           1      0.981     0.997     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.989     0.987     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.1604 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0035 Acc: 0.9991\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.985     0.987      4528\n",
      "           1      0.987     0.991     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0842 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0022 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0168 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.975     0.984      4528\n",
      "           1      0.980     0.994     0.987      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.986     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.3405 Acc: 0.9853\n",
      "Phase train\n",
      "PHASE train Loss: 0.0040 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.993     0.992      4528\n",
      "           1      0.994     0.992     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0301 Acc: 0.9924\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0024 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.989     0.989      4529\n",
      "           1      0.991     0.991     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0460 Acc: 0.9897\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.989     0.990      4529\n",
      "           1      0.991     0.992     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0802 Acc: 0.9905\n",
      "Phase train\n",
      "PHASE train Loss: 0.0036 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.976     0.983      4529\n",
      "           1      0.980     0.991     0.986      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.1188 Acc: 0.9843\n",
      "Phase train\n",
      "PHASE train Loss: 0.0027 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.987     0.989      4529\n",
      "           1      0.989     0.992     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0829 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0041 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.976     0.986      4529\n",
      "           1      0.980     0.996     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.986     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0839 Acc: 0.9869\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.991     0.982      4528\n",
      "           1      0.992     0.978     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.1584 Acc: 0.9838\n",
      "Phase train\n",
      "PHASE train Loss: 0.0033 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.995     0.984      4528\n",
      "           1      0.996     0.977     0.986      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.986     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.2387 Acc: 0.9854\n",
      "Phase train\n",
      "PHASE train Loss: 0.0020 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.969     0.996     0.982      4529\n",
      "           1      0.996     0.973     0.985      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.984     0.983      9928\n",
      "weighted avg      0.984     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.4734 Acc: 0.9834\n",
      "Phase train\n",
      "PHASE train Loss: 0.0024 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.952     0.994     0.973      4529\n",
      "           1      0.995     0.958     0.976      5399\n",
      "\n",
      "    accuracy                          0.974      9928\n",
      "   macro avg      0.973     0.976     0.974      9928\n",
      "weighted avg      0.975     0.974     0.974      9928\n",
      "\n",
      "PHASE val Loss: 1.6126 Acc: 0.9744\n",
      "Phase train\n",
      "PHASE train Loss: 0.0021 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4529\n",
      "           1      0.993     0.985     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.1584 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0018 Acc: 0.9997\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.992     0.981      4529\n",
      "           1      0.993     0.975     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.4384 Acc: 0.9827\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0012 Acc: 0.9999\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.990     0.988      4529\n",
      "           1      0.991     0.988     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0668 Acc: 0.9888\n",
      "Phase train\n",
      "PHASE train Loss: 0.0016 Acc: 0.9996\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.978     0.986      4528\n",
      "           1      0.982     0.995     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0909 Acc: 0.9873\n",
      "Phase train\n",
      "PHASE train Loss: 0.0017 Acc: 0.9996\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.976     0.985      4529\n",
      "           1      0.980     0.996     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.986     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.1785 Acc: 0.9867\n",
      "Phase train\n",
      "PHASE train Loss: 0.0024 Acc: 0.9992\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.981     0.981      4529\n",
      "           1      0.984     0.985     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.3639 Acc: 0.9829\n",
      "Phase train\n",
      "PHASE train Loss: 0.0042 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.990     0.985      4529\n",
      "           1      0.992     0.983     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.2357 Acc: 0.9861\n",
      "Phase train\n",
      "PHASE train Loss: 0.0023 Acc: 0.9995\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.958     0.975      4528\n",
      "           1      0.966     0.993     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.979     0.976     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.6783 Acc: 0.9771\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.937     0.966      4529\n",
      "           1      0.950     0.997     0.973      5399\n",
      "\n",
      "    accuracy                          0.970      9928\n",
      "   macro avg      0.973     0.967     0.969      9928\n",
      "weighted avg      0.971     0.970     0.970      9928\n",
      "\n",
      "PHASE val Loss: 1.1406 Acc: 0.9697\n",
      "Phase train\n",
      "PHASE train Loss: 0.0028 Acc: 0.9994\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.970     0.976      4528\n",
      "           1      0.975     0.986     0.980      5400\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.979     0.978     0.978      9928\n",
      "weighted avg      0.979     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.3350 Acc: 0.9786\n",
      "Phase train\n",
      "PHASE train Loss: 0.0060 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.969     0.973      4528\n",
      "           1      0.974     0.980     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.975     0.975     0.975      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.3181 Acc: 0.9752\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.996     0.986      4529\n",
      "           1      0.997     0.979     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.988     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.1456 Acc: 0.9868\n",
      "Phase train\n",
      "PHASE train Loss: 0.0054 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.997     0.967      4529\n",
      "           1      0.997     0.945     0.970      5399\n",
      "\n",
      "    accuracy                          0.969      9928\n",
      "   macro avg      0.968     0.971     0.968      9928\n",
      "weighted avg      0.970     0.969     0.969      9928\n",
      "\n",
      "PHASE val Loss: 3.1956 Acc: 0.9686\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.972     0.994     0.983      4529\n",
      "           1      0.995     0.976     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.4251 Acc: 0.9839\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.994     0.979      4529\n",
      "           1      0.995     0.969     0.982      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.980     0.982     0.980      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 1.1778 Acc: 0.9806\n",
      "Phase train\n",
      "PHASE train Loss: 0.0039 Acc: 0.9988\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.996     0.981      4529\n",
      "           1      0.996     0.971     0.984      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.983     0.982      9928\n",
      "weighted avg      0.983     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.9046 Acc: 0.9824\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.961     0.996     0.978      4529\n",
      "           1      0.997     0.966     0.981      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.979     0.981     0.980      9928\n",
      "weighted avg      0.981     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.6889 Acc: 0.9800\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.991     0.986      4529\n",
      "           1      0.993     0.984     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.988     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.2212 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.965     0.979      4528\n",
      "           1      0.972     0.994     0.982      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.979     0.980      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.4336 Acc: 0.9807\n",
      "Phase train\n",
      "PHASE train Loss: 0.0037 Acc: 0.9990\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.978     0.986      4529\n",
      "           1      0.982     0.996     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.987     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0692 Acc: 0.9877\n",
      "Phase train\n",
      "PHASE train Loss: 0.0037 Acc: 0.9990\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.971     0.974      4529\n",
      "           1      0.976     0.980     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.976     0.976     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.8300 Acc: 0.9761\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.966     0.976      4529\n",
      "           1      0.972     0.989     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.980     0.978     0.979      9928\n",
      "weighted avg      0.979     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.3767 Acc: 0.9787\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.959     0.998     0.978      4528\n",
      "           1      0.998     0.964     0.981      5400\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.978     0.981     0.979      9928\n",
      "weighted avg      0.980     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 1.2714 Acc: 0.9794\n",
      "Phase train\n",
      "PHASE train Loss: 0.0043 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.987     0.977      4528\n",
      "           1      0.989     0.972     0.980      5400\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.978     0.980     0.979      9928\n",
      "weighted avg      0.979     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.4766 Acc: 0.9788\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.981     0.985      4528\n",
      "           1      0.985     0.991     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.986     0.986      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0889 Acc: 0.9866\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.956     0.974      4529\n",
      "           1      0.964     0.994     0.979      5399\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.979     0.975     0.976      9928\n",
      "weighted avg      0.977     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.2985 Acc: 0.9767\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.933     0.963      4528\n",
      "           1      0.947     0.996     0.971      5400\n",
      "\n",
      "    accuracy                          0.967      9928\n",
      "   macro avg      0.971     0.965     0.967      9928\n",
      "weighted avg      0.969     0.967     0.967      9928\n",
      "\n",
      "PHASE val Loss: 3.1282 Acc: 0.9675\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.972     0.982      4529\n",
      "           1      0.977     0.994     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.983     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.5253 Acc: 0.9840\n",
      "Phase train\n",
      "PHASE train Loss: 0.0052 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.951     0.972      4529\n",
      "           1      0.960     0.995     0.977      5399\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.977     0.973     0.974      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 1.2900 Acc: 0.9747\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.954     0.994     0.974      4528\n",
      "           1      0.995     0.960     0.977      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.975     0.977     0.975      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.9046 Acc: 0.9755\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.982     0.980      4529\n",
      "           1      0.985     0.981     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.981     0.981     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.3302 Acc: 0.9813\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loaders = dict({'train': train_loader, 'val': val_loader})\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    bestmodel = train_valid_model (model,loaders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642055d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'densenet121best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d302589",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"densenet121\", pretrained=True)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe7b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b90f1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b347ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4197a13e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "9928\n",
      "Test Loss: 0.0711 Acc: 0.9889\n",
      "4436  /  4529\n",
      "5382  /  5399\n"
     ]
    }
   ],
   "source": [
    "y_test, y_prob, y_pred= test_best_model (model, test_loader, a_device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa3819e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c310a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.998\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_prob[:,1])\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d046468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curves and AUC\n",
    "plt.plot(fpr,tpr ,marker='.', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('DenseNet121 Fine-Tuning')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('DenseNet121 Fine-Tuning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afca02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9889202256244963\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred,normalize = True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0912897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9898841272760713\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053ee51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
