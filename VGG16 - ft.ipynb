{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1a30ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import openslide\n",
    "from skimage.color import rgb2hsv\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import pathlib\n",
    "import tables\n",
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import kl_div, softmax, log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7b2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_img', 'test_label', 'train_img', 'train_label', 'val_img', 'val_label']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_path = '/home/irene/Downloads/luadlusc.hdf5'\n",
    "file = h5py.File(hdf5_path, \"r\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c002ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean,rgb_std = (0.485, 0.456, 0.406),(0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0a9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, h5_path, set_name, transform = None):\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset = None\n",
    "        self.transform = transform\n",
    "        self.file_path  = h5_path\n",
    "        self.set = set_name\n",
    "        \n",
    "        str_name = self.set + \"_img\"\n",
    "        \n",
    "        file = h5py.File(h5_path, \"r\")\n",
    "        self.dataset_len = len(file[str_name])\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(rgb_mean,rgb_std)\n",
    "            ])\n",
    "        \n",
    "    def __getitem__(self, index): #to enable indexing\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.imgs = h5py.File(self.file_path, 'r')[self.set + \"_img\"]\n",
    "            self.labels = h5py.File(self.file_path, 'r')[self.set + \"_label\"]\n",
    "            \n",
    "            cur_img = self.imgs[index]\n",
    "            PIL_image = Image.fromarray(np.uint8(cur_img)).convert('RGB')#3 channels don't need alpha channel network input\n",
    "            image = self.transform(PIL_image)\n",
    "            label = self.labels[index].astype('float32')\n",
    "            \n",
    "            \n",
    "        return (image,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46da7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "train_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"train\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "val_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"val\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "test_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"test\"), batch_size=8,shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b3dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"vgg16\", pretrained=True)\n",
    "model.head.fc = nn.Linear(model.head.fc.in_features, out_dim)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train_valid_model (net,loaders,max_epochs = 20):\n",
    "    best_acc = 0.0 \n",
    "    for epoch in range (max_epochs):\n",
    "        for phase in ['train','val']:\n",
    "            iterator = iter(loaders[phase])\n",
    "            total_step = len(loaders[phase])\n",
    "            print('Phase {}'.format(phase))\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "            predictions_all = []\n",
    "            label_all = []\n",
    "            probs_all = []\n",
    "            for step in range(total_step-1): #iterate each batch\n",
    "                images,labels = next(iterator) # CUDA computation\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = net(images)\n",
    "                loss = criterion(output,labels)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(output, dim=1) # probabilities\n",
    "                \n",
    "                running_loss +=loss.item()\n",
    "                _, preds = torch.max(output.data,1)\n",
    "                \n",
    "                running_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                if len(predictions_all) == 0:\n",
    "                    predictions_all = preds.detach().cpu().numpy()\n",
    "                    label_all = labels.detach().cpu().numpy()\n",
    "                    probs_all = probs.detach().cpu().numpy()\n",
    "                else:\n",
    "                    predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                    probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "                    label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "                    \n",
    "            phase_loss = running_loss / len(loaders[phase])\n",
    "            phase_acc = running_correct/len(label_all.flatten())\n",
    "            if phase == 'val':\n",
    "                y_true = label_all.flatten()\n",
    "                y_pred = predictions_all.flatten()\n",
    "                print(\"validating...\")\n",
    "                print(len(y_true))\n",
    "                print(len(y_pred))\n",
    "                print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "            if phase == 'val' and phase_acc > best_acc:\n",
    "                \n",
    "                best_acc = phase_acc\n",
    "                import copy \n",
    "                \n",
    "                best_model_state_dict = copy.deepcopy(net.state_dict())\n",
    "                torch.save(best_model_state_dict,'vgg16best_model.pth')\n",
    "                \n",
    "            print('PHASE {} Loss: {:.4f} Acc: {:.4f}'.format(phase, phase_loss, phase_acc))\n",
    "    net.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    return net \n",
    "            \n",
    "       \n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd74f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model (net, test_loader, a_device = None):\n",
    "    iterator = iter(test_loader)\n",
    "    total_step = len(test_loader)\n",
    "    \n",
    "    print(total_step)\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        total_0,total_1 = 0,0\n",
    "        hit_0 = 0\n",
    "        hit_1 = 0\n",
    "        label_all = []\n",
    "        probs_all = []\n",
    "        predictions_all = []\n",
    "        for step in range(total_step-1):\n",
    "            images,labels = next(iterator)\n",
    "            images.to(a_device)\n",
    "            labels.to(a_device)\n",
    "            total_0 += labels.tolist().count(0)\n",
    "            total_1 += labels.tolist().count(1)\n",
    "            print(labels.shape)\n",
    "            images = images.to(a_device)\n",
    "            labels = labels.to(device=a_device, dtype=torch.int64)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            output = net(images)\n",
    "            loss = criterion(output,labels)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "            _, preds = torch.max(output.data,1)\n",
    "            \n",
    "            equals = preds == labels.view(*preds.shape)\n",
    "            if(len(label_all) ==0):\n",
    "                predictions_all = preds.detach().cpu().numpy()\n",
    "                label_all = labels.detach().cpu().numpy()\n",
    "                probs_all = probs.detach().cpu().numpy()\n",
    "            else:\n",
    "                predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "                probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "\n",
    "            all_hits = equals.view(equals.shape[0]).tolist() \n",
    "            all_corrects = labels[all_hits]\n",
    "            \n",
    "            hit_0 += all_corrects.tolist().count(0)\n",
    "            hit_1 += all_corrects.tolist().count(1)\n",
    " \n",
    "        \n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "        print(len(label_all.flatten()))\n",
    "        label_all = label_all.flatten()\n",
    "        predictions_all = predictions_all.flatten()\n",
    "        phase_loss = running_loss / len(test_loader)\n",
    "        phase_acc = running_corrects/len(label_all.flatten())\n",
    "        print('Test Loss: {:.4f} Acc: {:.4f}'.format(phase_loss, phase_acc))\n",
    "        \n",
    "        print(hit_0, ' / ',total_0)\n",
    "        print(hit_1, ' / ',total_1)\n",
    "                \n",
    "            \n",
    "    return label_all, probs_all, predictions_all #add this later\n",
    "                \n",
    "        #y_test --> label, y_score --> probs all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44d75601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (pre_logits): ConvMlp(\n",
       "    (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): ReLU(inplace=True)\n",
       "  )\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a59e4a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.4826 Acc: 0.7537\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.932     0.575     0.711      4529\n",
      "           1      0.730     0.965     0.831      5399\n",
      "\n",
      "    accuracy                          0.787      9928\n",
      "   macro avg      0.831     0.770     0.771      9928\n",
      "weighted avg      0.822     0.787     0.776      9928\n",
      "\n",
      "PHASE val Loss: 0.3950 Acc: 0.7870\n",
      "Phase train\n",
      "PHASE train Loss: 0.2897 Acc: 0.8707\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.901     0.938     0.919      4529\n",
      "           1      0.946     0.913     0.929      5399\n",
      "\n",
      "    accuracy                          0.925      9928\n",
      "   macro avg      0.923     0.926     0.924      9928\n",
      "weighted avg      0.925     0.925     0.925      9928\n",
      "\n",
      "PHASE val Loss: 0.1878 Acc: 0.9246\n",
      "Phase train\n",
      "PHASE train Loss: 0.1824 Acc: 0.9269\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.874     0.925      4529\n",
      "           1      0.903     0.986     0.943      5399\n",
      "\n",
      "    accuracy                          0.935      9928\n",
      "   macro avg      0.942     0.930     0.934      9928\n",
      "weighted avg      0.939     0.935     0.935      9928\n",
      "\n",
      "PHASE val Loss: 0.1561 Acc: 0.9351\n",
      "Phase train\n",
      "PHASE train Loss: 0.1245 Acc: 0.9516\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.866     0.983     0.921      4529\n",
      "           1      0.984     0.872     0.925      5399\n",
      "\n",
      "    accuracy                          0.923      9928\n",
      "   macro avg      0.925     0.928     0.923      9928\n",
      "weighted avg      0.930     0.923     0.923      9928\n",
      "\n",
      "PHASE val Loss: 0.1829 Acc: 0.9227\n",
      "Phase train\n",
      "PHASE train Loss: 0.0921 Acc: 0.9646\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.947     0.963      4529\n",
      "           1      0.957     0.984     0.970      5399\n",
      "\n",
      "    accuracy                          0.967      9928\n",
      "   macro avg      0.968     0.965     0.967      9928\n",
      "weighted avg      0.967     0.967     0.967      9928\n",
      "\n",
      "PHASE val Loss: 0.0875 Acc: 0.9671\n",
      "Phase train\n",
      "PHASE train Loss: 0.0586 Acc: 0.9783\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.990     0.963      4528\n",
      "           1      0.991     0.945     0.967      5400\n",
      "\n",
      "    accuracy                          0.965      9928\n",
      "   macro avg      0.964     0.967     0.965      9928\n",
      "weighted avg      0.967     0.965     0.965      9928\n",
      "\n",
      "PHASE val Loss: 0.0933 Acc: 0.9652\n",
      "Phase train\n",
      "PHASE train Loss: 0.0502 Acc: 0.9826\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.927     0.956     0.941      4528\n",
      "           1      0.962     0.937     0.949      5400\n",
      "\n",
      "    accuracy                          0.946      9928\n",
      "   macro avg      0.945     0.946     0.945      9928\n",
      "weighted avg      0.946     0.946     0.946      9928\n",
      "\n",
      "PHASE val Loss: 0.1592 Acc: 0.9456\n",
      "Phase train\n",
      "PHASE train Loss: 0.0447 Acc: 0.9839\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.990     0.980      4529\n",
      "           1      0.992     0.975     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.981     0.982     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0587 Acc: 0.9817\n",
      "Phase train\n",
      "PHASE train Loss: 0.0383 Acc: 0.9867\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.947     0.990     0.968      4529\n",
      "           1      0.992     0.953     0.972      5399\n",
      "\n",
      "    accuracy                          0.970      9928\n",
      "   macro avg      0.969     0.972     0.970      9928\n",
      "weighted avg      0.971     0.970     0.970      9928\n",
      "\n",
      "PHASE val Loss: 0.0915 Acc: 0.9701\n",
      "Phase train\n",
      "PHASE train Loss: 0.0304 Acc: 0.9890\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.984     0.986      4528\n",
      "           1      0.986     0.990     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0382 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0288 Acc: 0.9904\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.983     0.981      4528\n",
      "           1      0.986     0.983     0.984      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.982     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0502 Acc: 0.9827\n",
      "Phase train\n",
      "PHASE train Loss: 0.0233 Acc: 0.9921\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.983     0.986      4529\n",
      "           1      0.986     0.990     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0337 Acc: 0.9871\n",
      "Phase train\n",
      "PHASE train Loss: 0.0179 Acc: 0.9944\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.990     0.989      4529\n",
      "           1      0.991     0.991     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0291 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0174 Acc: 0.9942\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.994     0.989      4528\n",
      "           1      0.995     0.986     0.990      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0309 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0119 Acc: 0.9961\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.986     0.983      4529\n",
      "           1      0.988     0.983     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0524 Acc: 0.9841\n",
      "Phase train\n",
      "PHASE train Loss: 0.0077 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4528\n",
      "           1      0.991     0.993     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.989     0.989      4528\n",
      "           1      0.991     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0272 Acc: 0.9897\n",
      "Phase train\n",
      "PHASE train Loss: 0.0138 Acc: 0.9953\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.995     0.992      4529\n",
      "           1      0.996     0.991     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0262 Acc: 0.9925\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.986     0.986      4528\n",
      "           1      0.989     0.988     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0392 Acc: 0.9872\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0070 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.989     0.990      4529\n",
      "           1      0.991     0.993     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0284 Acc: 0.9910\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.953     0.985     0.969      4529\n",
      "           1      0.987     0.959     0.973      5399\n",
      "\n",
      "    accuracy                          0.971      9928\n",
      "   macro avg      0.970     0.972     0.971      9928\n",
      "weighted avg      0.972     0.971     0.971      9928\n",
      "\n",
      "PHASE val Loss: 0.1114 Acc: 0.9710\n",
      "Phase train\n",
      "PHASE train Loss: 0.0022 Acc: 0.9997\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.994      4529\n",
      "           1      0.996     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0188 Acc: 0.9949\n",
      "Phase train\n",
      "PHASE train Loss: 0.0001 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.995      4529\n",
      "           1      0.996     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0211 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0001 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.997     0.993      4529\n",
      "           1      0.997     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0236 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0001 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4529\n",
      "           1      0.996     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0209 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0199 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4528\n",
      "           1      0.996     0.995     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0191 Acc: 0.9952\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0201 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4529\n",
      "           1      0.997     0.995     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0210 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4529\n",
      "           1      0.996     0.995     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0207 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4529\n",
      "           1      0.996     0.995     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0218 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4528\n",
      "           1      0.997     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0220 Acc: 0.9949\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.995      4529\n",
      "           1      0.997     0.994     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0221 Acc: 0.9954\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4528\n",
      "           1      0.997     0.995     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0221 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.997     0.995      4529\n",
      "           1      0.997     0.994     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.996     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0218 Acc: 0.9955\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.995      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0239 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.996     0.995      4528\n",
      "           1      0.996     0.996     0.996      5400\n",
      "\n",
      "    accuracy                          0.996      9928\n",
      "   macro avg      0.996     0.996     0.996      9928\n",
      "weighted avg      0.996     0.996     0.996      9928\n",
      "\n",
      "PHASE val Loss: 0.0211 Acc: 0.9958\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4528\n",
      "           1      0.997     0.995     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.996     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0215 Acc: 0.9955\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.995      4528\n",
      "           1      0.996     0.995     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0210 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.997     0.995      4529\n",
      "           1      0.997     0.994     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0213 Acc: 0.9954\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0250 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0226 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0227 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0233 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0237 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.995      4529\n",
      "           1      0.996     0.995     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0224 Acc: 0.9951\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.996     0.995      4528\n",
      "           1      0.997     0.995     0.996      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.996     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0217 Acc: 0.9955\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.994     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0226 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0257 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0246 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.997     0.995      4529\n",
      "           1      0.997     0.994     0.996      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0232 Acc: 0.9953\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.994      4529\n",
      "           1      0.995     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0233 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0223 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.994     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0237 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.994     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0241 Acc: 0.9946\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0246 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0244 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0284 Acc: 0.9938\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0213 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0228 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0225 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0231 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.997     0.994      4529\n",
      "           1      0.997     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0241 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4528\n",
      "           1      0.997     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.994     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0258 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0221 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0227 Acc: 0.9949\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0224 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.995     0.994      4528\n",
      "           1      0.996     0.995     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0245 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0236 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0234 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0264 Acc: 0.9944\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0244 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0255 Acc: 0.9939\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0235 Acc: 0.9948\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0247 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0234 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.994     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0235 Acc: 0.9946\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0256 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0245 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0243 Acc: 0.9947\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0253 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0240 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0247 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0233 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.996     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0245 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4528\n",
      "           1      0.996     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.997     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0247 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9940\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0258 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.996     0.994      4529\n",
      "           1      0.997     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.995      9928\n",
      "   macro avg      0.995     0.995     0.995      9928\n",
      "weighted avg      0.995     0.995     0.995      9928\n",
      "\n",
      "PHASE val Loss: 0.0225 Acc: 0.9950\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0267 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.994      4528\n",
      "           1      0.995     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0257 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0258 Acc: 0.9936\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0249 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.993      4529\n",
      "           1      0.995     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0251 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0247 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0263 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0293 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0269 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0251 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0272 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0281 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0251 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0236 Acc: 0.9943\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0254 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0255 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.996     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0278 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0256 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.997     0.992     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0247 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9939\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0236 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0283 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0276 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0265 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0277 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.995     0.992      4529\n",
      "           1      0.996     0.991     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0289 Acc: 0.9928\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.997     0.993      4529\n",
      "           1      0.997     0.991     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0300 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0248 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0265 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.992      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0265 Acc: 0.9930\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0265 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.994     0.992      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0277 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0163 Acc: 0.9945\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.985     0.978      4529\n",
      "           1      0.987     0.975     0.981      5399\n",
      "\n",
      "    accuracy                          0.979      9928\n",
      "   macro avg      0.979     0.980     0.979      9928\n",
      "weighted avg      0.980     0.979     0.979      9928\n",
      "\n",
      "PHASE val Loss: 0.0600 Acc: 0.9795\n",
      "Phase train\n",
      "PHASE train Loss: 0.0576 Acc: 0.9804\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.978     0.979      4529\n",
      "           1      0.982     0.984     0.983      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.981     0.981     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0504 Acc: 0.9813\n",
      "Phase train\n",
      "PHASE train Loss: 0.0427 Acc: 0.9852\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.967     0.973      4528\n",
      "           1      0.972     0.983     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.976     0.975     0.975      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.0685 Acc: 0.9753\n",
      "Phase train\n",
      "PHASE train Loss: 0.0332 Acc: 0.9885\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.988     0.990      4528\n",
      "           1      0.990     0.994     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0275 Acc: 0.9908\n",
      "Phase train\n",
      "PHASE train Loss: 0.0281 Acc: 0.9904\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.972     0.982      4528\n",
      "           1      0.977     0.994     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.983     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0447 Acc: 0.9840\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0260 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0267 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0250 Acc: 0.9944\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0272 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0258 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0279 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0253 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.994     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0257 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.993      4529\n",
      "           1      0.995     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0273 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0255 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0252 Acc: 0.9935\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.995     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0239 Acc: 0.9945\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0235 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0283 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0261 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0267 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0277 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.994     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0277 Acc: 0.9935\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0260 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0279 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0275 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0270 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4528\n",
      "           1      0.994     0.992     0.993      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0289 Acc: 0.9927\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0278 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0286 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0269 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0265 Acc: 0.9939\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.996     0.993      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0289 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4528\n",
      "           1      0.997     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0279 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.992      4528\n",
      "           1      0.995     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0288 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0291 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0305 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0295 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.994     0.992      4529\n",
      "           1      0.995     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0304 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0283 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4528\n",
      "           1      0.997     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0264 Acc: 0.9940\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.995     0.994      4528\n",
      "           1      0.996     0.994     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0250 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4529\n",
      "           1      0.996     0.993     0.995      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0259 Acc: 0.9942\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0295 Acc: 0.9935\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0263 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0269 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4529\n",
      "           1      0.996     0.993     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0255 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0279 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.996     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0274 Acc: 0.9936\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.993      4529\n",
      "           1      0.996     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0288 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.995     0.993      4528\n",
      "           1      0.996     0.992     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.993     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0295 Acc: 0.9937\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.997     0.992     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0286 Acc: 0.9941\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4529\n",
      "           1      0.995     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0261 Acc: 0.9938\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.996     0.994      4528\n",
      "           1      0.997     0.993     0.995      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0283 Acc: 0.9943\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.992      4529\n",
      "           1      0.994     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0298 Acc: 0.9932\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.997     0.993      4529\n",
      "           1      0.997     0.992     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0302 Acc: 0.9940\n",
      "Phase train\n",
      "PHASE train Loss: 0.0000 Acc: 1.0000\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.993      4529\n",
      "           1      0.995     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0254 Acc: 0.9937\n",
      "Phase train\n",
      "PHASE train Loss: 0.3663 Acc: 0.7828\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.674     0.847     0.751      4528\n",
      "           1      0.836     0.657     0.736      5400\n",
      "\n",
      "    accuracy                          0.743      9928\n",
      "   macro avg      0.755     0.752     0.743      9928\n",
      "weighted avg      0.762     0.743     0.742      9928\n",
      "\n",
      "PHASE val Loss: 0.5041 Acc: 0.7434\n",
      "Phase train\n",
      "PHASE train Loss: 0.1917 Acc: 0.9193\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.925     0.977     0.950      4529\n",
      "           1      0.980     0.934     0.956      5399\n",
      "\n",
      "    accuracy                          0.954      9928\n",
      "   macro avg      0.953     0.955     0.953      9928\n",
      "weighted avg      0.955     0.954     0.954      9928\n",
      "\n",
      "PHASE val Loss: 0.1267 Acc: 0.9536\n",
      "Phase train\n",
      "PHASE train Loss: 0.0754 Acc: 0.9727\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.964     0.984     0.974      4528\n",
      "           1      0.987     0.969     0.978      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.975     0.977     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.0664 Acc: 0.9762\n",
      "Phase train\n",
      "PHASE train Loss: 0.0509 Acc: 0.9824\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.932     0.958      4529\n",
      "           1      0.946     0.988     0.966      5399\n",
      "\n",
      "    accuracy                          0.962      9928\n",
      "   macro avg      0.965     0.960     0.962      9928\n",
      "weighted avg      0.963     0.962     0.962      9928\n",
      "\n",
      "PHASE val Loss: 0.1004 Acc: 0.9624\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loaders = dict({'train': train_loader, 'val': val_loader})\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    bestmodel = train_valid_model (model,loaders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178aaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'vgg16best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db16b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"vgg16\", pretrained=True)\n",
    "model.head.fc = nn.Linear(model.head.fc.in_features, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d23f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7222b5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82707141",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80ee892b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "9928\n",
      "Test Loss: 0.0200 Acc: 0.9952\n",
      "4505  /  4528\n",
      "5375  /  5400\n"
     ]
    }
   ],
   "source": [
    "y_test, y_prob, y_pred= test_best_model (model, test_loader, a_device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f15d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ca8c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9928,)\n",
      "(9928, 2)\n",
      "(9928,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_prob.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abf88980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_prob[:,1])\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a887fe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curves and AUC\n",
    "plt.plot(fpr,tpr ,marker='.', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('VGG16 Fine-Tuning')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('VGG16 Fine-Tuning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa507427",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4a0446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9951651893634166\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c12d5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba7615e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9955547323578441\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f7405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
