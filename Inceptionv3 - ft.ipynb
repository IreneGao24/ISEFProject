{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b529a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "import openslide\n",
    "from skimage.color import rgb2hsv\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import os\n",
    "import pathlib\n",
    "import tables\n",
    "\n",
    "import torch\n",
    "from skimage import io, transform\n",
    "from sklearn import metrics\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import kl_div, softmax, log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c606e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['test_img', 'test_label', 'train_img', 'train_label', 'val_img', 'val_label']>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_path = '/home/irene/Downloads/luadlusc.hdf5'\n",
    "file = h5py.File(hdf5_path, \"r\")\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19135a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean,rgb_std = (0.485, 0.456, 0.406),(0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1099b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDF5Dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, h5_path, set_name, transform = None):\n",
    "        self.h5_path = h5_path\n",
    "        self.dataset = None\n",
    "        self.transform = transform\n",
    "        self.file_path  = h5_path\n",
    "        self.set = set_name\n",
    "        \n",
    "        str_name = self.set + \"_img\"\n",
    "        \n",
    "        file = h5py.File(h5_path, \"r\")\n",
    "        self.dataset_len = len(file[str_name])\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(rgb_mean,rgb_std)\n",
    "            ])\n",
    "        \n",
    "    def __getitem__(self, index): #to enable indexing\n",
    "        \n",
    "        if self.dataset is None:\n",
    "            self.imgs = h5py.File(self.file_path, 'r')[self.set + \"_img\"]\n",
    "            self.labels = h5py.File(self.file_path, 'r')[self.set + \"_label\"]\n",
    "            \n",
    "            cur_img = self.imgs[index]\n",
    "            PIL_image = Image.fromarray(np.uint8(cur_img)).convert('RGB')#3 channels don't need alpha channel network input\n",
    "            image = self.transform(PIL_image)\n",
    "            label = self.labels[index].astype('float32')\n",
    "            \n",
    "            \n",
    "        return (image,label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5712175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "train_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"train\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "val_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"val\"), batch_size=8,shuffle=True,drop_last=False)\n",
    "test_loader = DataLoader(HDF5Dataset(h5_path=hdf5_path,set_name=\"test\"), batch_size=8,shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124bb1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"inception_v3\", pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, out_dim)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train_valid_model (net,loaders,max_epochs = 20):\n",
    "    best_acc = 0.0 \n",
    "    for epoch in range (max_epochs):\n",
    "        for phase in ['train','val']:\n",
    "            iterator = iter(loaders[phase])\n",
    "            total_step = len(loaders[phase])\n",
    "            print('Phase {}'.format(phase))\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "            predictions_all = []\n",
    "            label_all = []\n",
    "            probs_all = []\n",
    "            for step in range(total_step-1): #iterate each batch\n",
    "                images,labels = next(iterator) # CUDA computation\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.long()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                output = net(images)\n",
    "                loss = criterion(output,labels)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(output, dim=1) # probabilities\n",
    "                \n",
    "                running_loss +=loss.item()\n",
    "                _, preds = torch.max(output.data,1)\n",
    "                \n",
    "                running_correct += (preds == labels).sum().item()\n",
    "                \n",
    "                if len(predictions_all) == 0:\n",
    "                    predictions_all = preds.detach().cpu().numpy()\n",
    "                    label_all = labels.detach().cpu().numpy()\n",
    "                    probs_all = probs.detach().cpu().numpy()\n",
    "                else:\n",
    "                    predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                    probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "                    label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "                    \n",
    "            phase_loss = running_loss / len(loaders[phase])\n",
    "            phase_acc = running_correct/len(label_all.flatten())\n",
    "            if phase == 'val':\n",
    "                y_true = label_all.flatten()\n",
    "                y_pred = predictions_all.flatten()\n",
    "                print(\"validating...\")\n",
    "                print(len(y_true))\n",
    "                print(len(y_pred))\n",
    "                print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "            if phase == 'val' and phase_acc > best_acc:\n",
    "                \n",
    "                best_acc = phase_acc\n",
    "                import copy \n",
    "                \n",
    "                best_model_state_dict = copy.deepcopy(net.state_dict())\n",
    "                torch.save(best_model_state_dict,'inceptionv3best_model.pth')\n",
    "                \n",
    "            print('PHASE {} Loss: {:.4f} Acc: {:.4f}'.format(phase, phase_loss, phase_acc))\n",
    "    net.load_state_dict(best_model_state_dict)\n",
    "    \n",
    "    return net \n",
    "            \n",
    "       \n",
    "print(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f9eef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model (net, test_loader, a_device = None):\n",
    "    iterator = iter(test_loader)\n",
    "    total_step = len(test_loader)\n",
    "    \n",
    "    print(total_step)\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        total_0,total_1 = 0,0\n",
    "        hit_0 = 0\n",
    "        hit_1 = 0\n",
    "        label_all = []\n",
    "        probs_all = []\n",
    "        predictions_all = []\n",
    "        for step in range(total_step-1):\n",
    "            images,labels = next(iterator)\n",
    "            images.to(a_device)\n",
    "            labels.to(a_device)\n",
    "            total_0 += labels.tolist().count(0)\n",
    "            total_1 += labels.tolist().count(1)\n",
    "            print(labels.shape)\n",
    "            images = images.to(a_device)\n",
    "            labels = labels.to(device=a_device, dtype=torch.int64)\n",
    "            labels = labels.long()\n",
    "            \n",
    "            output = net(images)\n",
    "            loss = criterion(output,labels)\n",
    "            \n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "            _, preds = torch.max(output.data,1)\n",
    "            \n",
    "            equals = preds == labels.view(*preds.shape)\n",
    "            if(len(label_all) ==0):\n",
    "                predictions_all = preds.detach().cpu().numpy()\n",
    "                label_all = labels.detach().cpu().numpy()\n",
    "                probs_all = probs.detach().cpu().numpy()\n",
    "            else:\n",
    "                predictions_all = np.vstack((predictions_all, preds.detach().cpu().numpy()))\n",
    "                label_all = np.vstack((label_all, labels.detach().cpu().numpy()))\n",
    "                probs_all = np.vstack((probs_all, probs.detach().cpu().numpy()))\n",
    "\n",
    "            all_hits = equals.view(equals.shape[0]).tolist() \n",
    "            all_corrects = labels[all_hits]\n",
    "            \n",
    "            hit_0 += all_corrects.tolist().count(0)\n",
    "            hit_1 += all_corrects.tolist().count(1)\n",
    " \n",
    "        \n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "        print(len(label_all.flatten()))\n",
    "        label_all = label_all.flatten()\n",
    "        predictions_all = predictions_all.flatten()\n",
    "        phase_loss = running_loss / len(test_loader)\n",
    "        phase_acc = running_corrects/len(label_all.flatten())\n",
    "        print('Test Loss: {:.4f} Acc: {:.4f}'.format(phase_loss, phase_acc))\n",
    "        \n",
    "        print(hit_0, ' / ',total_0)\n",
    "        print(hit_1, ' / ',total_1)\n",
    "                \n",
    "            \n",
    "    return label_all, probs_all, predictions_all #add this later\n",
    "                \n",
    "        #y_test --> label, y_score --> probs all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6ad9a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.4878 Acc: 0.7591\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.903     0.764     0.828      4529\n",
      "           1      0.825     0.931     0.875      5399\n",
      "\n",
      "    accuracy                          0.855      9928\n",
      "   macro avg      0.864     0.848     0.851      9928\n",
      "weighted avg      0.860     0.855     0.853      9928\n",
      "\n",
      "PHASE val Loss: 0.3121 Acc: 0.8550\n",
      "Phase train\n",
      "PHASE train Loss: 0.3371 Acc: 0.8520\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.908     0.933     0.920      4529\n",
      "           1      0.942     0.921     0.931      5399\n",
      "\n",
      "    accuracy                          0.926      9928\n",
      "   macro avg      0.925     0.927     0.926      9928\n",
      "weighted avg      0.927     0.926     0.926      9928\n",
      "\n",
      "PHASE val Loss: 0.1937 Acc: 0.9263\n",
      "Phase train\n",
      "PHASE train Loss: 0.2569 Acc: 0.8957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.962     0.924     0.943      4529\n",
      "           1      0.938     0.969     0.954      5399\n",
      "\n",
      "    accuracy                          0.949      9928\n",
      "   macro avg      0.950     0.947     0.948      9928\n",
      "weighted avg      0.949     0.949     0.949      9928\n",
      "\n",
      "PHASE val Loss: 0.1399 Acc: 0.9487\n",
      "Phase train\n",
      "PHASE train Loss: 0.2033 Acc: 0.9195\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.958     0.916     0.937      4529\n",
      "           1      0.932     0.967     0.949      5399\n",
      "\n",
      "    accuracy                          0.944      9928\n",
      "   macro avg      0.945     0.941     0.943      9928\n",
      "weighted avg      0.944     0.944     0.944      9928\n",
      "\n",
      "PHASE val Loss: 0.1811 Acc: 0.9437\n",
      "Phase train\n",
      "PHASE train Loss: 0.1735 Acc: 0.9338\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.966     0.959     0.962      4529\n",
      "           1      0.966     0.971     0.969      5399\n",
      "\n",
      "    accuracy                          0.966      9928\n",
      "   macro avg      0.966     0.965     0.965      9928\n",
      "weighted avg      0.966     0.966     0.966      9928\n",
      "\n",
      "PHASE val Loss: 0.0898 Acc: 0.9658\n",
      "Phase train\n",
      "PHASE train Loss: 0.1452 Acc: 0.9457\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.888     0.930      4528\n",
      "           1      0.912     0.982     0.946      5400\n",
      "\n",
      "    accuracy                          0.939      9928\n",
      "   macro avg      0.944     0.935     0.938      9928\n",
      "weighted avg      0.941     0.939     0.938      9928\n",
      "\n",
      "PHASE val Loss: 0.2502 Acc: 0.9388\n",
      "Phase train\n",
      "PHASE train Loss: 0.1238 Acc: 0.9528\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.960     0.964      4528\n",
      "           1      0.967     0.973     0.970      5400\n",
      "\n",
      "    accuracy                          0.967      9928\n",
      "   macro avg      0.967     0.966     0.967      9928\n",
      "weighted avg      0.967     0.967     0.967      9928\n",
      "\n",
      "PHASE val Loss: 0.0997 Acc: 0.9670\n",
      "Phase train\n",
      "PHASE train Loss: 0.1013 Acc: 0.9628\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.972     0.976      4528\n",
      "           1      0.977     0.982     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.978     0.977     0.978      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.0641 Acc: 0.9777\n",
      "Phase train\n",
      "PHASE train Loss: 0.0927 Acc: 0.9661\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.955     0.967      4528\n",
      "           1      0.963     0.983     0.973      5400\n",
      "\n",
      "    accuracy                          0.970      9928\n",
      "   macro avg      0.971     0.969     0.970      9928\n",
      "weighted avg      0.970     0.970     0.970      9928\n",
      "\n",
      "PHASE val Loss: 0.0833 Acc: 0.9699\n",
      "Phase train\n",
      "PHASE train Loss: 0.0754 Acc: 0.9728\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.975     0.975      4528\n",
      "           1      0.979     0.979     0.979      5400\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.977     0.977     0.977      9928\n",
      "weighted avg      0.977     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.0716 Acc: 0.9773\n",
      "Phase train\n",
      "PHASE train Loss: 0.0642 Acc: 0.9764\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.972     0.974      4529\n",
      "           1      0.976     0.980     0.978      5399\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.976     0.976     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.0803 Acc: 0.9761\n",
      "Phase train\n",
      "PHASE train Loss: 0.0670 Acc: 0.9755\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.939     0.963      4528\n",
      "           1      0.951     0.990     0.970      5400\n",
      "\n",
      "    accuracy                          0.967      9928\n",
      "   macro avg      0.970     0.965     0.967      9928\n",
      "weighted avg      0.968     0.967     0.967      9928\n",
      "\n",
      "PHASE val Loss: 0.0943 Acc: 0.9671\n",
      "Phase train\n",
      "PHASE train Loss: 0.0572 Acc: 0.9797\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.987     0.979      4528\n",
      "           1      0.989     0.975     0.982      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.980     0.981     0.981      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0551 Acc: 0.9807\n",
      "Phase train\n",
      "PHASE train Loss: 0.0512 Acc: 0.9811\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.984     0.982      4529\n",
      "           1      0.986     0.983     0.985      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0512 Acc: 0.9834\n",
      "Phase train\n",
      "PHASE train Loss: 0.0481 Acc: 0.9825\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.985     0.985      4529\n",
      "           1      0.987     0.988     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0412 Acc: 0.9867\n",
      "Phase train\n",
      "PHASE train Loss: 0.0444 Acc: 0.9835\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.958     0.973      4528\n",
      "           1      0.966     0.991     0.978      5400\n",
      "\n",
      "    accuracy                          0.976      9928\n",
      "   macro avg      0.977     0.974     0.976      9928\n",
      "weighted avg      0.976     0.976     0.976      9928\n",
      "\n",
      "PHASE val Loss: 0.0693 Acc: 0.9758\n",
      "Phase train\n",
      "PHASE train Loss: 0.0322 Acc: 0.9884\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.986     0.983      4528\n",
      "           1      0.988     0.983     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0531 Acc: 0.9841\n",
      "Phase train\n",
      "PHASE train Loss: 0.0400 Acc: 0.9853\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.967     0.978      4528\n",
      "           1      0.973     0.992     0.982      5400\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.981     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.0532 Acc: 0.9805\n",
      "Phase train\n",
      "PHASE train Loss: 0.0306 Acc: 0.9894\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.965     0.993     0.979      4529\n",
      "           1      0.994     0.970     0.982      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.980     0.982     0.980      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0582 Acc: 0.9806\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0247 Acc: 0.9915\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.968     0.980      4529\n",
      "           1      0.974     0.993     0.983      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.983     0.981     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0581 Acc: 0.9819\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0406 Acc: 0.9855\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.985     0.983      4528\n",
      "           1      0.987     0.984     0.986      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0486 Acc: 0.9845\n",
      "Phase train\n",
      "PHASE train Loss: 0.0416 Acc: 0.9860\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.980     0.982      4529\n",
      "           1      0.983     0.987     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.983     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0471 Acc: 0.9838\n",
      "Phase train\n",
      "PHASE train Loss: 0.0370 Acc: 0.9866\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.987     0.987      4528\n",
      "           1      0.989     0.989     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0380 Acc: 0.9880\n",
      "Phase train\n",
      "PHASE train Loss: 0.0295 Acc: 0.9891\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.981     0.986      4528\n",
      "           1      0.984     0.992     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.986     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0382 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0294 Acc: 0.9894\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.983     0.985      4529\n",
      "           1      0.986     0.988     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0458 Acc: 0.9859\n",
      "Phase train\n",
      "PHASE train Loss: 0.0327 Acc: 0.9885\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.982     0.984      4529\n",
      "           1      0.985     0.989     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.985     0.985      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0444 Acc: 0.9856\n",
      "Phase train\n",
      "PHASE train Loss: 0.0262 Acc: 0.9905\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.989     0.985      4528\n",
      "           1      0.991     0.984     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0428 Acc: 0.9866\n",
      "Phase train\n",
      "PHASE train Loss: 0.0300 Acc: 0.9889\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.980     0.983      4528\n",
      "           1      0.983     0.988     0.986      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0443 Acc: 0.9845\n",
      "Phase train\n",
      "PHASE train Loss: 0.0261 Acc: 0.9907\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.995     0.949     0.972      4528\n",
      "           1      0.959     0.996     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.977     0.973     0.974      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.0758 Acc: 0.9747\n",
      "Phase train\n",
      "PHASE train Loss: 0.0241 Acc: 0.9915\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.991     0.989      4528\n",
      "           1      0.992     0.989     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0350 Acc: 0.9898\n",
      "Phase train\n",
      "PHASE train Loss: 0.0244 Acc: 0.9916\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.977     0.983      4529\n",
      "           1      0.981     0.992     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.984     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0411 Acc: 0.9850\n",
      "Phase train\n",
      "PHASE train Loss: 0.0189 Acc: 0.9939\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.960     0.972      4528\n",
      "           1      0.967     0.987     0.977      5400\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.976     0.974     0.974      9928\n",
      "weighted avg      0.975     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.1486 Acc: 0.9747\n",
      "Phase train\n",
      "PHASE train Loss: 0.0135 Acc: 0.9953\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.975     0.984      4528\n",
      "           1      0.980     0.994     0.987      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.986     0.985     0.985      9928\n",
      "weighted avg      0.986     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0436 Acc: 0.9855\n",
      "Phase train\n",
      "PHASE train Loss: 0.0190 Acc: 0.9933\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.977     0.984      4529\n",
      "           1      0.981     0.992     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.986     0.984     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0512 Acc: 0.9851\n",
      "Phase train\n",
      "PHASE train Loss: 0.0166 Acc: 0.9942\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.964     0.975      4528\n",
      "           1      0.971     0.989     0.980      5400\n",
      "\n",
      "    accuracy                          0.978      9928\n",
      "   macro avg      0.978     0.976     0.977      9928\n",
      "weighted avg      0.978     0.978     0.978      9928\n",
      "\n",
      "PHASE val Loss: 0.0744 Acc: 0.9775\n",
      "Phase train\n",
      "PHASE train Loss: 0.0135 Acc: 0.9953\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.995     0.987      4528\n",
      "           1      0.995     0.982     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0401 Acc: 0.9880\n",
      "Phase train\n",
      "PHASE train Loss: 0.0181 Acc: 0.9935\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.985     0.986      4529\n",
      "           1      0.987     0.989     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0452 Acc: 0.9871\n",
      "Phase train\n",
      "PHASE train Loss: 0.0203 Acc: 0.9930\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.991     0.989      4528\n",
      "           1      0.993     0.989     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE val Loss: 0.0372 Acc: 0.9900\n",
      "Phase train\n",
      "PHASE train Loss: 0.0187 Acc: 0.9930\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.984     0.988      4528\n",
      "           1      0.987     0.994     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.990     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0298 Acc: 0.9894\n",
      "Phase train\n",
      "PHASE train Loss: 0.0136 Acc: 0.9953\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.991     0.985      4529\n",
      "           1      0.993     0.981     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.985     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0496 Acc: 0.9860\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0147 Acc: 0.9951\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.956     0.975      4529\n",
      "           1      0.964     0.995     0.979      5399\n",
      "\n",
      "    accuracy                          0.977      9928\n",
      "   macro avg      0.979     0.976     0.977      9928\n",
      "weighted avg      0.978     0.977     0.977      9928\n",
      "\n",
      "PHASE val Loss: 0.0625 Acc: 0.9773\n",
      "Phase train\n",
      "PHASE train Loss: 0.0120 Acc: 0.9956\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.994     0.988      4528\n",
      "           1      0.995     0.985     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.990     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0362 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0124 Acc: 0.9957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.991     0.989      4529\n",
      "           1      0.992     0.989     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0317 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0190 Acc: 0.9928\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.987     0.987      4528\n",
      "           1      0.989     0.989     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0361 Acc: 0.9880\n",
      "Phase train\n",
      "PHASE train Loss: 0.0174 Acc: 0.9939\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.994     0.989      4529\n",
      "           1      0.995     0.986     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0370 Acc: 0.9898\n",
      "Phase train\n",
      "PHASE train Loss: 0.0164 Acc: 0.9941\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.987     0.989      4529\n",
      "           1      0.989     0.993     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0355 Acc: 0.9899\n",
      "Phase train\n",
      "PHASE train Loss: 0.0124 Acc: 0.9956\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.991     0.987      4529\n",
      "           1      0.992     0.986     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0413 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0144 Acc: 0.9948\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.991     0.988      4528\n",
      "           1      0.992     0.988     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0379 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0151 Acc: 0.9951\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.990     0.986      4528\n",
      "           1      0.991     0.985     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0407 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0129 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.989     0.988      4528\n",
      "           1      0.991     0.990     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0303 Acc: 0.9893\n",
      "Phase train\n",
      "PHASE train Loss: 0.0107 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.994     0.991      4528\n",
      "           1      0.995     0.990     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0296 Acc: 0.9919\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.985     0.989      4529\n",
      "           1      0.988     0.995     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0325 Acc: 0.9904\n",
      "Phase train\n",
      "PHASE train Loss: 0.0097 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.994     0.993      4528\n",
      "           1      0.995     0.994     0.994      5400\n",
      "\n",
      "    accuracy                          0.994      9928\n",
      "   macro avg      0.994     0.994     0.994      9928\n",
      "weighted avg      0.994     0.994     0.994      9928\n",
      "\n",
      "PHASE val Loss: 0.0299 Acc: 0.9939\n",
      "Phase train\n",
      "PHASE train Loss: 0.0085 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4529\n",
      "           1      0.991     0.993     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0372 Acc: 0.9915\n",
      "Phase train\n",
      "PHASE train Loss: 0.0118 Acc: 0.9958\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.991     0.989      4528\n",
      "           1      0.992     0.989     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0410 Acc: 0.9898\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.994     0.987      4528\n",
      "           1      0.995     0.983     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0555 Acc: 0.9880\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.994     0.990      4529\n",
      "           1      0.995     0.989     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0335 Acc: 0.9911\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0128 Acc: 0.9959\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.986     0.986      4529\n",
      "           1      0.988     0.988     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0480 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4529\n",
      "           1      0.993     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0718 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0098 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.996     0.989      4528\n",
      "           1      0.997     0.985     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0491 Acc: 0.9899\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0097 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.991     0.987      4528\n",
      "           1      0.993     0.986     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0445 Acc: 0.9882\n",
      "Phase train\n",
      "PHASE train Loss: 0.0087 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.986     0.989      4528\n",
      "           1      0.988     0.994     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0396 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0118 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.977     0.981      4528\n",
      "           1      0.981     0.987     0.984      5400\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.982     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0580 Acc: 0.9828\n",
      "Phase train\n",
      "PHASE train Loss: 0.0139 Acc: 0.9951\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.994     0.988      4529\n",
      "           1      0.995     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0404 Acc: 0.9885\n",
      "Phase train\n",
      "PHASE train Loss: 0.0087 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.987     0.988      4529\n",
      "           1      0.989     0.990     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0368 Acc: 0.9886\n",
      "Phase train\n",
      "PHASE train Loss: 0.0105 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.986     0.987      4529\n",
      "           1      0.988     0.990     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0426 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0133 Acc: 0.9954\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.979     0.986      4529\n",
      "           1      0.983     0.994     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.987     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0414 Acc: 0.9876\n",
      "Phase train\n",
      "PHASE train Loss: 0.0112 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.984     0.985      4529\n",
      "           1      0.987     0.988     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0471 Acc: 0.9863\n",
      "Phase train\n",
      "PHASE train Loss: 0.0103 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.988     0.986      4529\n",
      "           1      0.990     0.986     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0471 Acc: 0.9868\n",
      "Phase train\n",
      "PHASE train Loss: 0.0108 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.976     0.982      4528\n",
      "           1      0.980     0.991     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.985     0.983     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0522 Acc: 0.9841\n",
      "Phase train\n",
      "PHASE train Loss: 0.0097 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.993     0.988      4529\n",
      "           1      0.994     0.985     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0371 Acc: 0.9890\n",
      "Phase train\n",
      "PHASE train Loss: 0.0129 Acc: 0.9955\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.991     0.988      4529\n",
      "           1      0.993     0.986     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0476 Acc: 0.9886\n",
      "Phase train\n",
      "PHASE train Loss: 0.0103 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.988     0.990      4529\n",
      "           1      0.990     0.994     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0308 Acc: 0.9911\n",
      "Phase train\n",
      "PHASE train Loss: 0.0084 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.993     0.987      4529\n",
      "           1      0.994     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0395 Acc: 0.9882\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.990      4529\n",
      "           1      0.993     0.990     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0311 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0092 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.990     0.987      4528\n",
      "           1      0.992     0.986     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0629 Acc: 0.9881\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0109 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.983     0.987      4529\n",
      "           1      0.986     0.992     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0493 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.989     0.990      4529\n",
      "           1      0.991     0.991     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0448 Acc: 0.9904\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4528\n",
      "           1      0.994     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0316 Acc: 0.9929\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.990     0.990      4529\n",
      "           1      0.991     0.992     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0308 Acc: 0.9910\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0124 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.982     0.988      4529\n",
      "           1      0.985     0.994     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0374 Acc: 0.9889\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.990      4529\n",
      "           1      0.993     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0334 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0085 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.986     0.989      4529\n",
      "           1      0.988     0.994     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.991     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0363 Acc: 0.9904\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.992     0.989      4529\n",
      "           1      0.994     0.988     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0362 Acc: 0.9900\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.996     0.992      4528\n",
      "           1      0.997     0.990     0.993      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0304 Acc: 0.9925\n",
      "Phase train\n",
      "PHASE train Loss: 0.0027 Acc: 0.9993\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.994     0.993      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0303 Acc: 0.9933\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.993     0.984      4529\n",
      "           1      0.994     0.979     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.985     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0571 Acc: 0.9857\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.993     0.989      4529\n",
      "           1      0.994     0.988     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0367 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.994     0.991      4528\n",
      "           1      0.995     0.989     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0307 Acc: 0.9917\n",
      "Phase train\n",
      "PHASE train Loss: 0.0056 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.974     0.982      4529\n",
      "           1      0.978     0.991     0.985      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.984     0.983     0.983      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0523 Acc: 0.9834\n",
      "Phase train\n",
      "PHASE train Loss: 0.0102 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.994     0.989      4529\n",
      "           1      0.995     0.986     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0347 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0068 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.993     0.992      4529\n",
      "           1      0.994     0.992     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0272 Acc: 0.9925\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.967     0.978      4529\n",
      "           1      0.973     0.992     0.982      5399\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.982     0.979     0.980      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0722 Acc: 0.9806\n",
      "Phase train\n",
      "PHASE train Loss: 0.0036 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.992     0.992      4529\n",
      "           1      0.993     0.993     0.993      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0338 Acc: 0.9926\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.975     0.984      4529\n",
      "           1      0.979     0.994     0.986      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.986     0.984     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0571 Acc: 0.9852\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0102 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.991     0.989      4528\n",
      "           1      0.992     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0368 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0125 Acc: 0.9953\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.994     0.987      4528\n",
      "           1      0.995     0.983     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0458 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.987     0.989      4529\n",
      "           1      0.989     0.993     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0373 Acc: 0.9903\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.993     0.991      4529\n",
      "           1      0.994     0.990     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0367 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0113 Acc: 0.9957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.991     0.989      4528\n",
      "           1      0.992     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0464 Acc: 0.9901\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.988     0.991      4528\n",
      "           1      0.990     0.995     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0321 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.985     0.984      4528\n",
      "           1      0.988     0.985     0.986      5400\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.985     0.985      9928\n",
      "weighted avg      0.985     0.985     0.985      9928\n",
      "\n",
      "PHASE val Loss: 0.0548 Acc: 0.9851\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.993     0.987      4529\n",
      "           1      0.994     0.983     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0546 Acc: 0.9876\n",
      "Phase train\n",
      "PHASE train Loss: 0.0094 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.984     0.985      4529\n",
      "           1      0.987     0.988     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.986     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0532 Acc: 0.9861\n",
      "Phase train\n",
      "PHASE train Loss: 0.0082 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.988     0.989      4529\n",
      "           1      0.990     0.992     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0333 Acc: 0.9902\n",
      "Phase train\n",
      "PHASE train Loss: 0.0078 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.984     0.987      4528\n",
      "           1      0.987     0.992     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0406 Acc: 0.9886\n",
      "Phase train\n",
      "PHASE train Loss: 0.0094 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.988     0.990      4529\n",
      "           1      0.990     0.993     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0346 Acc: 0.9907\n",
      "Phase train\n",
      "PHASE train Loss: 0.0105 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.992     0.991      4529\n",
      "           1      0.994     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0403 Acc: 0.9918\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.985     0.989      4528\n",
      "           1      0.988     0.994     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0312 Acc: 0.9900\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.992     0.988      4529\n",
      "           1      0.993     0.987     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0391 Acc: 0.9892\n",
      "Phase train\n",
      "PHASE train Loss: 0.0109 Acc: 0.9962\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.988     0.985      4528\n",
      "           1      0.990     0.985     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0629 Acc: 0.9867\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.985     0.987      4528\n",
      "           1      0.988     0.991     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0425 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0096 Acc: 0.9964\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.991     0.990      4528\n",
      "           1      0.992     0.991     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0305 Acc: 0.9910\n",
      "Phase train\n",
      "PHASE train Loss: 0.0090 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.988     0.987      4529\n",
      "           1      0.990     0.988     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0405 Acc: 0.9882\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0080 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.987     0.986      4528\n",
      "           1      0.989     0.988     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0666 Acc: 0.9873\n",
      "Phase train\n",
      "PHASE train Loss: 0.0099 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.985     0.988      4528\n",
      "           1      0.987     0.992     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0458 Acc: 0.9889\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.978     0.982      4529\n",
      "           1      0.982     0.988     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.983     0.983      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0636 Acc: 0.9836\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.995     0.991      4528\n",
      "           1      0.996     0.988     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0441 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.992     0.989      4529\n",
      "           1      0.993     0.989     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0461 Acc: 0.9903\n",
      "Phase train\n",
      "PHASE train Loss: 0.0055 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.990     0.989      4528\n",
      "           1      0.991     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0388 Acc: 0.9898\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0103 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.986     0.986      4529\n",
      "           1      0.988     0.988     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0443 Acc: 0.9871\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4528\n",
      "           1      0.991     0.993     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0365 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0090 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.988     0.988      4529\n",
      "           1      0.990     0.991     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0383 Acc: 0.9894\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.991     0.986      4529\n",
      "           1      0.993     0.983     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0537 Acc: 0.9867\n",
      "Phase train\n",
      "PHASE train Loss: 0.0104 Acc: 0.9960\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.991     0.990      4529\n",
      "           1      0.992     0.990     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.990      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0342 Acc: 0.9905\n",
      "Phase train\n",
      "PHASE train Loss: 0.0132 Acc: 0.9950\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.995     0.989      4529\n",
      "           1      0.996     0.985     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0437 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.987     0.991      4528\n",
      "           1      0.989     0.995     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0370 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0079 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.994     0.988      4529\n",
      "           1      0.995     0.985     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.990     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0432 Acc: 0.9894\n",
      "Phase train\n",
      "PHASE train Loss: 0.0087 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.986     0.986      4529\n",
      "           1      0.988     0.989     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0447 Acc: 0.9872\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.991     0.990      4529\n",
      "           1      0.992     0.992     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0358 Acc: 0.9912\n",
      "Phase train\n",
      "PHASE train Loss: 0.0078 Acc: 0.9977\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.986     0.988      4529\n",
      "           1      0.988     0.991     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0431 Acc: 0.9888\n",
      "Phase train\n",
      "PHASE train Loss: 0.0083 Acc: 0.9970\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.995     0.986      4528\n",
      "           1      0.996     0.980     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.988     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0457 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.984     0.986      4528\n",
      "           1      0.987     0.990     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0443 Acc: 0.9873\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0074 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.979     0.993     0.986      4528\n",
      "           1      0.994     0.982     0.988      5400\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.986     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0473 Acc: 0.9869\n",
      "Phase train\n",
      "PHASE train Loss: 0.0080 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.989     0.990      4528\n",
      "           1      0.991     0.993     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0333 Acc: 0.9911\n",
      "Phase train\n",
      "PHASE train Loss: 0.0073 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4528\n",
      "           1      0.991     0.993     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0325 Acc: 0.9914\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.988     0.989      4529\n",
      "           1      0.990     0.992     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0397 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0047 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.988     0.990      4528\n",
      "           1      0.990     0.994     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0328 Acc: 0.9910\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.991     0.991      4528\n",
      "           1      0.992     0.993     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0373 Acc: 0.9918\n",
      "Phase train\n",
      "PHASE train Loss: 0.0110 Acc: 0.9960\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.991     0.988      4528\n",
      "           1      0.992     0.987     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0386 Acc: 0.9887\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0032 Acc: 0.9989\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.985     0.988      4529\n",
      "           1      0.988     0.992     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0390 Acc: 0.9890\n",
      "Phase train\n",
      "PHASE train Loss: 0.0080 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.991     0.990      4528\n",
      "           1      0.993     0.990     0.991      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0331 Acc: 0.9907\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.986     0.987      4528\n",
      "           1      0.988     0.991     0.989      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0392 Acc: 0.9885\n",
      "Phase train\n",
      "PHASE train Loss: 0.0076 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.991     0.989      4529\n",
      "           1      0.992     0.989     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0343 Acc: 0.9899\n",
      "Phase train\n",
      "PHASE train Loss: 0.0046 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.996     0.988      4529\n",
      "           1      0.996     0.983     0.989      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0414 Acc: 0.9886\n",
      "Phase train\n",
      "PHASE train Loss: 0.0148 Acc: 0.9946\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.987     0.986      4529\n",
      "           1      0.989     0.987     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0454 Acc: 0.9870\n",
      "Phase train\n",
      "PHASE train Loss: 0.0097 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.983     0.983      4529\n",
      "           1      0.986     0.985     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.984     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0555 Acc: 0.9842\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.985     0.988      4528\n",
      "           1      0.987     0.993     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0324 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0072 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.989     0.988      4529\n",
      "           1      0.991     0.990     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0368 Acc: 0.9893\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.994     0.992      4528\n",
      "           1      0.995     0.993     0.994      5400\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0257 Acc: 0.9930\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.972     0.980      4529\n",
      "           1      0.977     0.991     0.984      5399\n",
      "\n",
      "    accuracy                          0.982      9928\n",
      "   macro avg      0.983     0.981     0.982      9928\n",
      "weighted avg      0.982     0.982     0.982      9928\n",
      "\n",
      "PHASE val Loss: 0.0665 Acc: 0.9820\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9971\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.983     0.986      4529\n",
      "           1      0.986     0.991     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.987     0.987     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0549 Acc: 0.9872\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0058 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.976     0.986      4529\n",
      "           1      0.980     0.996     0.988      5399\n",
      "\n",
      "    accuracy                          0.987      9928\n",
      "   macro avg      0.988     0.986     0.987      9928\n",
      "weighted avg      0.987     0.987     0.987      9928\n",
      "\n",
      "PHASE val Loss: 0.0444 Acc: 0.9871\n",
      "Phase train\n",
      "PHASE train Loss: 0.0048 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.993     0.991      4529\n",
      "           1      0.994     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0361 Acc: 0.9916\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.992     0.990      4529\n",
      "           1      0.993     0.990     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0398 Acc: 0.9908\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.985     0.987      4528\n",
      "           1      0.987     0.991     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0411 Acc: 0.9882\n",
      "Phase train\n",
      "PHASE train Loss: 0.0064 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.995     0.985      4528\n",
      "           1      0.995     0.979     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.987     0.986      9928\n",
      "weighted avg      0.987     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0555 Acc: 0.9864\n",
      "Phase train\n",
      "PHASE train Loss: 0.0093 Acc: 0.9969\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.982     0.992     0.987      4529\n",
      "           1      0.993     0.985     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0492 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0066 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.988     0.987      4528\n",
      "           1      0.990     0.989     0.989      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0460 Acc: 0.9885\n",
      "Phase train\n",
      "PHASE train Loss: 0.0086 Acc: 0.9972\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.989     0.991      4529\n",
      "           1      0.991     0.994     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0317 Acc: 0.9914\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.989     0.987      4528\n",
      "           1      0.991     0.988     0.989      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0454 Acc: 0.9885\n",
      "Phase train\n",
      "PHASE train Loss: 0.0081 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.993     0.985      4528\n",
      "           1      0.994     0.980     0.987      5400\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.987     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0518 Acc: 0.9862\n",
      "Phase train\n",
      "PHASE train Loss: 0.0098 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.985     0.987      4528\n",
      "           1      0.987     0.991     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0355 Acc: 0.9878\n",
      "Phase train\n",
      "PHASE train Loss: 0.0102 Acc: 0.9963\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.964     0.978      4529\n",
      "           1      0.971     0.994     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.0608 Acc: 0.9802\n",
      "Phase train\n",
      "PHASE train Loss: 0.0088 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.980     0.994     0.987      4528\n",
      "           1      0.995     0.983     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0479 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0085 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.988     0.988      4528\n",
      "           1      0.990     0.990     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0436 Acc: 0.9891\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.990     0.991      4529\n",
      "           1      0.991     0.993     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.991     0.991      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0314 Acc: 0.9915\n",
      "Phase train\n",
      "PHASE train Loss: 0.0049 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.989     0.985      4529\n",
      "           1      0.991     0.984     0.987      5399\n",
      "\n",
      "    accuracy                          0.986      9928\n",
      "   macro avg      0.986     0.987     0.986      9928\n",
      "weighted avg      0.986     0.986     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0538 Acc: 0.9864\n",
      "Phase train\n",
      "PHASE train Loss: 0.0102 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.973     0.979      4528\n",
      "           1      0.977     0.987     0.982      5400\n",
      "\n",
      "    accuracy                          0.981      9928\n",
      "   macro avg      0.981     0.980     0.980      9928\n",
      "weighted avg      0.981     0.981     0.981      9928\n",
      "\n",
      "PHASE val Loss: 0.0800 Acc: 0.9807\n",
      "Phase train\n",
      "PHASE train Loss: 0.0092 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.966     0.978      4529\n",
      "           1      0.972     0.991     0.982      5399\n",
      "\n",
      "    accuracy                          0.980      9928\n",
      "   macro avg      0.981     0.979     0.980      9928\n",
      "weighted avg      0.980     0.980     0.980      9928\n",
      "\n",
      "PHASE val Loss: 0.0872 Acc: 0.9799\n",
      "Phase train\n",
      "PHASE train Loss: 0.0064 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.998     0.988      4528\n",
      "           1      0.998     0.981     0.989      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0410 Acc: 0.9885\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0045 Acc: 0.9986\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.992     0.990      4529\n",
      "           1      0.994     0.989     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.990      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0336 Acc: 0.9905\n",
      "Phase train\n",
      "PHASE train Loss: 0.0065 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.989     0.990      4528\n",
      "           1      0.990     0.993     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0369 Acc: 0.9908\n",
      "Phase train\n",
      "PHASE train Loss: 0.0044 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.993     0.993      4529\n",
      "           1      0.994     0.994     0.994      5399\n",
      "\n",
      "    accuracy                          0.993      9928\n",
      "   macro avg      0.993     0.993     0.993      9928\n",
      "weighted avg      0.993     0.993     0.993      9928\n",
      "\n",
      "PHASE val Loss: 0.0242 Acc: 0.9934\n",
      "Phase train\n",
      "PHASE train Loss: 0.0101 Acc: 0.9967\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.976     0.989     0.982      4528\n",
      "           1      0.991     0.979     0.985      5400\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.984     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0555 Acc: 0.9837\n",
      "Phase train\n",
      "PHASE train Loss: 0.0078 Acc: 0.9975\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.995     0.992      4528\n",
      "           1      0.996     0.991     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.993     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0284 Acc: 0.9924\n",
      "Phase train\n",
      "PHASE train Loss: 0.0063 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.975     0.994     0.984      4529\n",
      "           1      0.995     0.979     0.987      5399\n",
      "\n",
      "    accuracy                          0.985      9928\n",
      "   macro avg      0.985     0.986     0.985      9928\n",
      "weighted avg      0.986     0.985     0.986      9928\n",
      "\n",
      "PHASE val Loss: 0.0562 Acc: 0.9855\n",
      "Phase train\n",
      "PHASE train Loss: 0.0089 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     0.951     0.972      4529\n",
      "           1      0.961     0.996     0.978      5399\n",
      "\n",
      "    accuracy                          0.975      9928\n",
      "   macro avg      0.978     0.973     0.975      9928\n",
      "weighted avg      0.976     0.975     0.975      9928\n",
      "\n",
      "PHASE val Loss: 0.0753 Acc: 0.9754\n",
      "Phase train\n",
      "PHASE train Loss: 0.0053 Acc: 0.9984\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.992     0.989      4528\n",
      "           1      0.993     0.989     0.991      5400\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0397 Acc: 0.9901\n",
      "Phase train\n",
      "PHASE train Loss: 0.0058 Acc: 0.9980\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.991      4529\n",
      "           1      0.994     0.991     0.992      5399\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0373 Acc: 0.9915\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Phase train\n",
      "PHASE train Loss: 0.0069 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.991     0.992      4528\n",
      "           1      0.993     0.994     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0249 Acc: 0.9924\n",
      "Phase train\n",
      "PHASE train Loss: 0.0051 Acc: 0.9985\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.985     0.994     0.990      4529\n",
      "           1      0.995     0.988     0.991      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.990     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0301 Acc: 0.9907\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.993     0.990      4528\n",
      "           1      0.994     0.990     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0341 Acc: 0.9910\n",
      "Phase train\n",
      "PHASE train Loss: 0.0095 Acc: 0.9966\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.984     0.992     0.988      4529\n",
      "           1      0.993     0.986     0.990      5399\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.988     0.989     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0505 Acc: 0.9887\n",
      "Phase train\n",
      "PHASE train Loss: 0.0123 Acc: 0.9957\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.992     0.991      4528\n",
      "           1      0.993     0.991     0.992      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.991     0.992     0.991      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0324 Acc: 0.9915\n",
      "Phase train\n",
      "PHASE train Loss: 0.0096 Acc: 0.9965\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.990     0.989      4529\n",
      "           1      0.992     0.989     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.989     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0404 Acc: 0.9896\n",
      "Phase train\n",
      "PHASE train Loss: 0.0124 Acc: 0.9959\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.988     0.987      4528\n",
      "           1      0.990     0.989     0.989      5400\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0364 Acc: 0.9883\n",
      "Phase train\n",
      "PHASE train Loss: 0.0058 Acc: 0.9983\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.992     0.991      4528\n",
      "           1      0.993     0.992     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0289 Acc: 0.9920\n",
      "Phase train\n",
      "PHASE train Loss: 0.0068 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.981     0.993     0.987      4529\n",
      "           1      0.994     0.984     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.989     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0491 Acc: 0.9881\n",
      "Phase train\n",
      "PHASE train Loss: 0.0075 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.986     0.989      4529\n",
      "           1      0.988     0.993     0.991      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.990     0.990      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0405 Acc: 0.9898\n",
      "Phase train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE train Loss: 0.0050 Acc: 0.9982\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.992     0.990      4528\n",
      "           1      0.993     0.990     0.992      5400\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0306 Acc: 0.9910\n",
      "Phase train\n",
      "PHASE train Loss: 0.0071 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.974     0.992     0.983      4529\n",
      "           1      0.993     0.978     0.985      5399\n",
      "\n",
      "    accuracy                          0.984      9928\n",
      "   macro avg      0.983     0.985     0.984      9928\n",
      "weighted avg      0.984     0.984     0.984      9928\n",
      "\n",
      "PHASE val Loss: 0.0617 Acc: 0.9841\n",
      "Phase train\n",
      "PHASE train Loss: 0.0059 Acc: 0.9981\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.990     0.987      4529\n",
      "           1      0.992     0.986     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.987     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0502 Acc: 0.9878\n",
      "Phase train\n",
      "PHASE train Loss: 0.0061 Acc: 0.9979\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.983     0.991     0.987      4529\n",
      "           1      0.992     0.985     0.989      5399\n",
      "\n",
      "    accuracy                          0.988      9928\n",
      "   macro avg      0.988     0.988     0.988      9928\n",
      "weighted avg      0.988     0.988     0.988      9928\n",
      "\n",
      "PHASE val Loss: 0.0618 Acc: 0.9879\n",
      "Phase train\n",
      "PHASE train Loss: 0.0042 Acc: 0.9987\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.991     0.991     0.991      4528\n",
      "           1      0.993     0.993     0.993      5400\n",
      "\n",
      "    accuracy                          0.992      9928\n",
      "   macro avg      0.992     0.992     0.992      9928\n",
      "weighted avg      0.992     0.992     0.992      9928\n",
      "\n",
      "PHASE val Loss: 0.0298 Acc: 0.9919\n",
      "Phase train\n",
      "PHASE train Loss: 0.0074 Acc: 0.9976\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.975     0.981      4529\n",
      "           1      0.979     0.989     0.984      5399\n",
      "\n",
      "    accuracy                          0.983      9928\n",
      "   macro avg      0.983     0.982     0.982      9928\n",
      "weighted avg      0.983     0.983     0.983      9928\n",
      "\n",
      "PHASE val Loss: 0.0806 Acc: 0.9826\n",
      "Phase train\n",
      "PHASE train Loss: 0.0079 Acc: 0.9974\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.983     0.988      4528\n",
      "           1      0.986     0.993     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0362 Acc: 0.9888\n",
      "Phase train\n",
      "PHASE train Loss: 0.0096 Acc: 0.9968\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.982     0.988      4528\n",
      "           1      0.985     0.994     0.990      5400\n",
      "\n",
      "    accuracy                          0.989      9928\n",
      "   macro avg      0.989     0.988     0.989      9928\n",
      "weighted avg      0.989     0.989     0.989      9928\n",
      "\n",
      "PHASE val Loss: 0.0460 Acc: 0.9887\n",
      "Phase train\n",
      "PHASE train Loss: 0.0070 Acc: 0.9973\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.987     0.989      4529\n",
      "           1      0.989     0.991     0.990      5399\n",
      "\n",
      "    accuracy                          0.990      9928\n",
      "   macro avg      0.990     0.989     0.989      9928\n",
      "weighted avg      0.990     0.990     0.990      9928\n",
      "\n",
      "PHASE val Loss: 0.0400 Acc: 0.9895\n",
      "Phase train\n",
      "PHASE train Loss: 0.0062 Acc: 0.9978\n",
      "Phase val\n",
      "validating...\n",
      "9928\n",
      "9928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     0.987     0.990      4529\n",
      "           1      0.989     0.994     0.992      5399\n",
      "\n",
      "    accuracy                          0.991      9928\n",
      "   macro avg      0.991     0.991     0.991      9928\n",
      "weighted avg      0.991     0.991     0.991      9928\n",
      "\n",
      "PHASE val Loss: 0.0336 Acc: 0.9908\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loaders = dict({'train': train_loader, 'val': val_loader})\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    bestmodel = train_valid_model (model,loaders)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e02e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'inceptionv3best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "223e815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out_dim = 2\n",
    "\n",
    "model = timm.create_model(\"inception_v3\", pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e4aa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5720e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb5bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001,weight_decay = 1e-4,momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755e075e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "9928\n",
      "Test Loss: 0.0324 Acc: 0.9902\n",
      "4458  /  4528\n",
      "5373  /  5400\n"
     ]
    }
   ],
   "source": [
    "y_test, y_prob, y_pred= test_best_model (model, test_loader, a_device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "579f21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08162da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 1.000\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(y_test, y_prob[:,1])\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e188cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA690lEQVR4nO3deZxN9f/A8dfbjHXsRJbSQswYM2PLvmfL1k6UFkKiIrLVl1J+KkVCkaSiVEooSkqIVGRihizJMqGQZEhmef/+uHfGGDN3rjF3ztyZ9/PxuI+5557PPec9x7jv+/l8znkfUVWMMcaY9ORzOgBjjDE5myUKY4wxHlmiMMYY45ElCmOMMR5ZojDGGOORJQpjjDEeWaIwuYaIjBaR2U7H4Q0RWS4i9zgdR0ZEpJeIrHA6DuMssesoTGaIyF6gr6qudGj/LYF5qlo5m/dbFlgM1AACgO3AMFVdl077uUBP4GyKl/uo6vtZHFczYHnSIlAEOJWiSYiq7s/KfZq8I9DpAIzxM7HA/cAuQIFuwFIRKaeq8em853lVfcKXQanqWqAogIhcBfwGlPQQkzFes6Enc8lE5F4R+VZEJonIcRH5TUQ6plhfWkTeFJGD7vWfpFjXWUQiReRvEVkvImEp1u0VkVEiss39vjdFpJCIBOH69lxRRGLdj4oiMk5E5qV4f1cRiXZv+xsRCU617WEiskVETojI+yJSyL1uu4h0TtE2UESOikgdVT2jqjtUNRHXN/cEoBRQ+iKP2Tci0tfL41dCRN4QkUMi8ruIPCMiAZnZV8r9pVhWERkgIrvc+58uIpKJtgEi8qL7WP0mIoPc7e0LqZ+zRGGySgNgB1AWeB54I+kDBHgH11BITaAcMBlAROoAc4D+QBlgJrBERAqm2G4voD1wLXAd8ISqngI6AgdVtaj7cTBlMCJyHfAe8ChwGbAM1zf/Aima3QF0AK4GwoB73a+/B9yZol174Kiq/pRi+1uAM8ASYLaq/untgUqHp+P3FhAPVAVqA+2Avmlt5BJ0BuoD4biOS/tMtH0A179LBFAHuCmLYzQOsURhsso+VX1dVRNwfbBVAMqLSAVcHx4DVPW4qsap6mr3ex4AZqrq96qaoKpvAf8BDVNsd5qqHlDVv4BnOf8D3JPuwGeq+qWqxgGTgMJA4xRtpqrqQfe2l+L6gAN4F+gqIkXcyz3dryVT1TCguHvdt3g2zN2r+VtEjqbTJr3jVx7X8XtUVU+5E9JkoEdGB+AiTVTVv93zGKs4dywupu0dwMuqGqOqx4GJWRyjcYglCpNVDic9UdXT7qdFgSuAv9wfHKlVAR5L8SH6t7t9xRRtDqR4vi/VOk8qutsnxZTo3laltGIGTrvjRVV345qk7uJOFl1JlSjc7c6o6nvASBEJ9xDLJFUt6X6UTadNesevCpAfOJTiGM3E1TPDPbSWNPzWzEMMGUnzWFxk24qc/++V8rnxYzZ2aHztAFBaREqq6t9prHtWVZ/18P4rUjy/EkgaYsrodL2DQK2kBfcwzhXA794Ezbnhp3zANnfySE9+4BrgZy+3fTEO4OpllU1rYlpVa3qxjVO4hv6SXJ5FsaV2CEh5FtoV6TU0/sV6FManVPUQronnGSJSSkTyi0hz9+rXgQEi0kBcgkSkk4gUS7GJh0SksoiUBkYDSaeV/gGUEZES6ez6A6CTiLQRkfzAY7g+cNd7GfoCXHMBD5KiNyEiDUWkqYgUEJHCIjICKA987+V2L4r7+K0AXhSR4iKST0SuFZEWF7GZSOAWESkiIlWBPr6IFdcxf0REKolISWCEj/ZjspklCpMd7gbigF+AP3FNMKOqG3HNU0wDjgO7OTehnORdXB+Ue9yPZ9zv/QXXt/497iGZ84akVHUHcBfwCnAU6AJ0UdWU1zOky/0B/R2uOY2U1zwUBKYDx3D1Tm4EOqWeTM9ivYECwDZcx2khrjkMb03GdR3HH7jmP+ZndYBur+P6t9oCbMZ1AkE8rjPDjB+zC+5MjiUOX9RnLo37FN/XVLWK07GYS2M9CmNMlnAPxd3ovu6kEjAWWOR0XObS+SxRiMgcEflTRKLSWS8iMlVEdrsveqrjq1iMMdlCgKdwDY9txnXm2P8cjchkCZ8NPbknLGOBt1U1NI31NwKDcY3xNsB1/nUDnwRjjDEm03zWo1DVNcBfHpp0w5VEVFU3ACXdF2cZY4zJQZy8jqIS51+QE+N+7VDqhiLSD+gHEBQUVLdGjRqcPpvAr0diszyoAgH5yB+Qdv78Lz6B+MRzPbDAfELBwPNL7pyJSyAhRS8tQIRC+S++ja+dTUgkLiHxvNfyB+SjQDq/e2blhN/VmLzs1N9HOHvyL/IVKkbC6ROS8Tsu5GSiSCvgNMfBVHUWMAugXr16WvneKUTGnLio8wO9VbxQIMEViqe5bs/RWI6cPHd2Zc8GVzLh5lrntXn3+/2MXrQ1eXnCzbXo2eDKi27ja5v2HefOWd9xNsF1yAsE5uO9BxpSt0qpLN1PTvhdjcmLVBUR4aXZ7zJ+5nucPrA90/MMTiaKGM6/crMy5666TddvR09xNOaEz4Ia2TE43Q+ypA/XuAQlf4Bwa50Lb4WQ9N7lUYfoGFohzW1508bX6lYpxXv9GvHRTzEIcEudylmeJCBn/K7G5CXHjx9n2LBhXHPNNYwZM4ahfXvSom1HGoRWy/S1Pj69jkJcdfE/TWcyuxMwiHOT2VNV9fqMtlmwQjWtcM8Ur/ZfMEC4okwQ9ze5GnB9WJUJKsCxU2eTf3YMrZC8zpsPsk37jrNhzzEaXlPGJx+sxhiTWYsWLWLgwIEcOXKEJ554gnHjxiWvE5FNqlovM9v15VlP7wEtcZVN/gPXOdX5AVT1NXftnWm4yjyfBu5zX6nrUXqJ4rKiBfjxibZZFb4xxviNP/74g8GDB/Phhx8SERHBG2+8QZ06519xcCmJwmdDT6rqsRy0ujLUQ1mxr70TO2XFZowxxi8dOHCAzz77jGeffZbhw4eTP3/+LN2+31ePHdD8GqdDMMaYbLdv3z6WLl3KoEGDqFevHvv376dMmTI+2Zffl/AYeWNwxo2MMSaXSExMZPr06YSGhjJq1CgOHXJdUeCrJAG5IFEYY0xesWPHDlq0aMGgQYNo0qQJUVFRVKjg++uU/XroKfjyYhk3MsaYXOD06dM0bdqUhIQE5s6dS+/evTl3W3Xf8utE8Uyqi92MMSa32blzJ9WqVaNIkSK88847REREcPnlvrpJYdr8duip2mVBdh2DMSbXOnPmDGPGjCEkJIT58133murQoUO2Jwnw4x7F5SULOx2CMcb4xLp16+jTpw87duzgvvvuo1MnZy8B8NseRdIV1cYYk5uMHz+eZs2acebMGb744gvmzJlDqVLOjp74XaIQXNdOWM0gY0xuklQlIyIigsGDBxMVFUW7du0cjsrF7xKFAq9/+xub9h13OhRjjLlkf/31F/fccw/PPPMMAF26dOHll1+maNGiDkd2jt8lCoCEROW55dudDsMYYy7JwoULCQ4O5t1338WXBVovld9OZm8/fNLpEIwxJlMOHTrEoEGD+Pjjj6lbty4rVqwgPDzc6bDS5Zc9CoB8fhu5MSavO3jwIF988QXPPfccGzZsyNFJAvy4R3FZUEGnQzDGGK/t3buXpUuXMnjwYOrWrcuBAwccP5vJW377vfz+plY11hiT8yUkJDB16lRCQ0MZM2YMhw8fBvCbJAF+nCiMMSan2759O82bN+eRRx6hWbNmREVFOXJl9aXy20QxZeUOp0Mwxph0nT59mubNm/PLL7/w9ttvs2zZMq680j+v//LbOYqjsWedDsEYYy7wyy+/UL16dYoUKcL8+fMJDw+nfPnyTod1Sfy2R0HOPeXYGJMH/fvvv4wYMYKaNWsmF/Fr166d3ycJ8OMeRf6A7KnDbowxGVmzZg19+/Zl165d9O3bl86dOzsdUpby2x5FgvUojDE5wFNPPUWLFi2Ij49n5cqVvP7665QsWdLpsLKU3yaKxETLFMYY5ySV3KhXrx5Dhgxh69attGnTxuGofMN/E4XTARhj8qSjR49y9913M378eAA6derESy+9RFBQkMOR+Y7fJgpjjMlOqsoHH3xASEgICxYsIF8eqiPkt5PZxQoGOB2CMSaPOHjwIAMHDmTx4sXUq1ePlStXEhYW5nRY2cZvU2LtK/3n8ndjjH87fPgwX3/9NS+88ALfffddnkoS4Mc9irW7jzodgjEmF9uzZw9Llizh0UcfpU6dOuzfvz/Xnc3kLb/tUeTge3wYY/xYQkICkydPJjQ0lLFjxyYX8curSQL8OFEYY0xWi46OpkmTJgwdOpTWrVsTHR3tl0X8sprfDj0ZY0xWOn36NC1atEBEePfdd+nRowciVgECLFEYY/K4bdu2ERwcTJEiRViwYAHh4eFcdtllToeVo9jQkzEmTzp9+jTDhw+nVq1azJs3D4AbbrjBkkQarEdhjMlzvvnmGx544AF2795N//796dq1q9Mh5WjWozDG5Cljx46lVatWqCpff/01r732GiVKlHA6rBzNEoUxJk9IKuJ3/fXX89hjj7FlyxZatWrlcFT+waeJQkQ6iMgOEdktIiPTWF9CRJaKyM8iEi0i9/kyHmNM3nPkyBF69uzJ008/DbiK+E2aNIkiRYo4HJn/8FmiEJEAYDrQEQgB7hSRkFTNHgK2qWo40BJ4UUQK+ComY0zeoaq8++67BAcHs3DhQgoUsI+WzPJlj+J6YLeq7lHVs8ACoFuqNgoUE9fJykWBv4B4H8ZkjMkDYmJi6Nq1K7169aJq1aps3ryZUaNGOR2W3/JloqgEHEixHON+LaVpQDBwENgKPKKqF9xqQkT6ichGEdnoq2CNMbnHkSNHWLNmDS+99BLr1q2jZs2aTofk13yZKNK6pDF1hab2QCRQEYgApolI8QvepDpLVeupar2sDtIYkzvs3r2byZMnA1C7dm0OHDjAkCFDCAiwWxJcKl8mihjgihTLlXH1HFK6D/hYXXYDvwE1fBiTMSaXiY+PZ9KkSdSqVYunnnqKP/74A4DixS/4zmkyyZeJ4kegmohc7Z6g7gEsSdVmP9AGQETKA9WBPT6MyRiTi2zdupXGjRszfPhw2rVrR3R0NOXLl3c6rFzHZ1dmq2q8iAwCvgACgDmqGi0iA9zrXwPGA3NFZCuuoaoRqmo3mjDGZOj06dO0atWKfPnysWDBAu644w4r4ucjPi3hoarLgGWpXnstxfODQDtfxmCMyV2ioqKoWbMmRYoU4f333yc8PJyyZcs6HVauZldmG2P8wqlTpxg6dChhYWHJRfzatGljSSIbWFFAY0yO99VXX/HAAw/w22+/MXDgQLp1S31JlvEl61EYY3K0J598khtuuIHAwEBWr17N9OnT7YymbGaJwhiTIyUmuq69bdy4MY8//jg///wzzZs3dziqvMkShTEmR/nzzz/p0aMHTz31FAAdO3bkueeeo3Dhwg5HlndZojDG5Aiqyrx58wgODmbRokVW3TUHsURhjHHcgQMH6Ny5M3fffTfVq1dn8+bNjBgxwumwjJvfJgq7rMaY3OPYsWOsW7eOl19+mbVr1xISkvqOBMZJfnt6bOrqgsYY/7Jz506WLFnCsGHDiIiI4MCBAxQrVszpsEwarEdhjMlW8fHxPPfcc4SFhfHss88mF/GzJJFz+W2isB6FMf7n559/pkGDBowcOZIbb7yRbdu2WRE/P+C3Q0/GGP9y+vRp2rRpQ2BgIAsXLuTWW291OiTjJb9NFDb0ZIx/2LJlC7Vq1aJIkSJ8+OGHhIeHU7p0aafDMhfBb4ee8vlt5MbkDbGxsTzyyCNERETwzjvvANCqVStLEn7IehTGmCz35Zdf0q9fP/bu3cugQYO4+eabnQ7JXAK//V6uNpttTI40ZswY2rVrR8GCBVm7di2vvPKKndHk57xOFCIS5MtALlahAnbDdGNykqQifk2bNmXUqFFERkbStGlTh6MyWSHDRCEijUVkG7DdvRwuIjN8HlkGCluiMCZHOHz4MLfddhvjxo0DXEX8JkyYQKFChZwNzGQZb3oUk4H2wDEAVf0ZsFq/xuRxqsrcuXMJCQnh008/tXtE5GJeTWar6oFUNy1P8E043ouPT3Q6BGPyrH379tGvXz9WrFhB06ZNmT17NtWrV3c6LOMj3vQoDohIY0BFpICIDMM9DOWkhESbzTbGKX///Tc//vgj06ZNY/Xq1ZYkcjlvehQDgJeBSkAMsAIY6MugvBFUwG/P7DXGL+3YsYMlS5YwfPhwwsPD2b9/P0WLFnU6LJMNvOlRVFfVXqpaXlXLqepdQLCvA8vI2QQbejImO8TFxfF///d/hIeHM3HiRP78808ASxJ5iDeJ4hUvX8tWxQrldzoEY3K9zZs306BBA0aPHk2XLl3Ytm0b5cqVczosk83SHb8RkUZAY+AyERmaYlVxwPFzU0sWsURhjC+dPn2atm3bkj9/fj766CNuueUWp0MyDvE00F8AKOpuk/Kyyn+A23wZlDeuLpujrv8zJtfYvHkzERERFClShIULFxIeHk6pUqWcDss4KN1EoaqrgdUiMldV92VjTF757egpp0MwJlc5efIko0aNYvr06bz11lv07t2bli1bOh2WyQG8OXXotIi8ANQEki+1VNXWPovKC2ftOgpjssznn39O//79OXDgAI888ogNM5nzeDOZPR/4BbgaeArYC/zow5i8EmdnPRmTJUaNGkXHjh0JCgpi3bp1TJkyxc5oMufxpkdRRlXfEJFHUgxHrfZ1YBkpHVTA6RCM8WsJCQkEBATQsmVLAgMDeeKJJyhYsKDTYZkcyJtEEef+eUhEOgEHgcq+C8k7JYtYojAmMw4dOsRDDz1EzZo1GT9+PO3bt6d9+/ZOh2VyMG+Gnp4RkRLAY8AwYDbwqC+DMsZkPVXlzTffJCQkhOXLl9uZTMZrGfYoVPVT99MTQCsAEWniy6CMMVlr7969PPDAA6xcuZJmzZoxe/ZsrrvuOqfDMn7C0wV3AcAduGo8fa6qUSLSGRgNFAZqZ0+IxphLdeLECX766SdmzJhB//79yWc3nTcXwVOP4g3gCuAHYKqI7AMaASNV9RNvNi4iHXAVFAwAZqvqxDTatASmAPmBo6rawvvwjTHp2bZtG0uWLGHkyJHJRfyCguxCVXPxPCWKekCYqiaKSCHgKFBVVQ97s2F3j2Q60BZX1dkfRWSJqm5L0aYkMAPooKr7RcSKyBhzic6ePcvzzz/P+PHjKVasGPfffz/lypWzJGEyzVP/86yqJgKo6hlgp7dJwu16YLeq7lHVs8ACoFuqNj2Bj1V1v3s/f17E9o0xqWzcuJH69evz5JNPcsstt1gRP5MlPPUoaojIFvdzAa51LwugqhqWwbYrAQdSLMcADVK1uQ7ILyLf4Kon9bKqvp16QyLSD+gHUODyqgCULWbnexuT0qlTp2jfvj2FChVi8eLFdO3a1emQTC7hKVFc6j0nJI3XUt+WLhCoC7TBNUH+nYhsUNWd571JdRYwC6BghWoKEFqxxCWGZ0zu8NNPPxEREUFQUBCLFi0iLCyMkiVLOh2WyUXSHXpS1X2eHl5sOwbXZHiSyrgu1kvd5nNVPaWqR4E1QLg3gUcfPOFNM2NyrX/++YeBAwdSt25d5s2bB0Dz5s0tSZgs58tz5H4EqonI1SJSAOgBLEnVZjHQTEQCRaQIrqEpr+7HfeTkf1karDH+ZNmyZdSsWZOZM2cydOhQbr31VqdDMrmYzxKFqsYDg4AvcH34f6Cq0SIyQEQGuNtsBz4HtuA6DXe2qkZ5s32bozB51YgRI+jUqRPFixdn/fr1vPjii3ZGk/Epb2o9ISKFgStVdcfFbFxVlwHLUr32WqrlF4AXLma7YHMUJm9RVRITEwkICKBNmzYUKlSI0aNHWxE/ky0y7FGISBcgEtc3f0QkQkRSDyFlO5ujMHnF77//zk033cTYsWMBaNeuHU899ZQlCZNtvBl6Gofrmoi/AVQ1ErjKVwF5K/XpU8bkNqrK66+/TkhICCtWrKBs2bJOh2TyKG+GnuJV9YRIWme7OseGnkxu9ttvv9GnTx9WrVpFy5Ytef3116latarTYZk8yptEESUiPYEAEakGPAys921Ynglw/PRZJ0MwxqdiY2PZsmULM2fOpG/fvlbEzzjKm7++wbjul/0f8C6ucuOP+jCmDClQym5cZHKZqKgoJkyYAECtWrXYv38//fr1syRhHOfNX2B1VR2jqvXdjyfctZ8ckw/rUZjc4+zZszz11FPUqVOHyZMn8+efrpJnRYoUcTgyY1y8SRQvicgvIjJeRGr6PCIvBAbmo+E1ZZwOw5hL9uOPP1K3bl3GjRvH7bffbkX8TI7kzR3uWonI5bhuYjRLRIoD76vqMz6PLv2gHNu1MVnl1KlTdOjQgcKFC7NkyRK6dOnidEjGpMmrwU9VPayqU4EBuK6p+J8vg8pIfKKyYc8xJ0MwJtM2btxIYmIiQUFBLF68mOjoaEsSJkfz5oK7YBEZJyJRwDRcZzxV9nlkHiSqTWYb/3PixAn69+9P/fr1k4v4NW3alBIl7FRvk7N5c3rsm8B7QDtVTV391RE2mW38zdKlSxkwYACHDx9m2LBh3HbbbU6HZIzXvJmjaJgdgVwMm8w2/mT48OFMmjSJWrVq8cknn1C/fn2nQzLmoqSbKETkA1W9Q0S2cn7FDG/vcOc7NpltcjhVJSEhgcDAQNq1a0fx4sUZMWIEBQrYkKnxP556FI+4f3bOjkAuRoJ7MrtulVJOh2LMBWJiYnjwwQcJCwvj2WefpW3btrRt29bpsIzJNE93uDvkfjowjbvbDcye8NKW34aeTA6UmJjIzJkzCQkJ4euvv+byyy93OiRjsoQ3p8em9VWoY1YH4q0AEf7Xuab1JkyOsmfPHlq3bs2AAQO4/vrr2bp1K4MHD3Y6LGOyRLqJQkQedM9PVBeRLSkev+G6I50jElR5+tNoNu077lQIxlzg1KlTbNu2jdmzZ/Pll19yzTXXOB2SMVnG0xzFu8By4P+AkSleP6mqf/k0qgzExSfaHIVx3NatW1m8eDFPPPEEtWrVYt++fRQuXNjpsIzJcp6GnlRV9wIPASdTPBCR0r4PLX02R2Gc9N9///G///2POnXqMHXq1OQifpYkTG6VUY+iM7AJ1+mxKe9cpIAjfWubozBO2rBhA3369GHbtm3cfffdTJ48mTJl7EuLyd3STRSq2tn98+rsCydjSXMU1S8vZsnCZKtTp07RqVMngoKCWLZsGR07OnZOhzHZyptaT01EJMj9/C4ReUlErvR9aOlLmqMwJjt8//33yUX8li5dSnR0tCUJk6d4c3rsq8BpEQkHHgf2Ae/4NKoM2ByFyQ5///03ffv2pWHDhslF/Bo3bkyxYsUcjsyY7OVNoohXVQW6AS+r6suAY/9T8gfkY37fhjbsZHzqk08+ISQkhLlz5zJixAhuv/12p0MyxjHeVI89KSKjgLuBZiISAOT3bVjGOGfo0KFMnjyZ8PBwli5dSt26dZ0OyRhHedOj6A78B9yvqoeBSsALPo3Kg7iERHrN3mAX3JksparEx8cDcOONN/LMM88k36bUmLwuw0ThTg7zgRIi0hk4o6pv+zwyD2wy22Sl/fv306lTJ8aOHQvADTfcwJgxY8if3zrOxoB3Zz3dAfwA3I7rvtnfi4ijd12xyWyTFRITE5kxYwY1a9Zk9erVVKxY0emQjMmRvJmjGAPUV9U/AUTkMmAlsNCXgaXHJrNNVti9ezf3338/a9eupW3btsyaNYurrrrK6bCMyZG8SRT5kpKE2zG8m9vwiQIB+SxJmEt25swZdu7cyZtvvsk999yDiGT8JmPyKG8Sxeci8gWu+2aDa3J7me9C8uxsQiKb9h23ZGEuWmRkJIsXL2bs2LGEhoayd+9eChUq5HRYxuR43kxmDwdmAmFAODBLVUf4OrD02FlP5mKdOXOGMWPGUK9ePV599dXkIn6WJIzxjqf7UVQTkcUiEoVrIvtFVR2iqouyL7y02VlPxlvr16+ndu3aTJgwgbvuuott27ZRrlw5p8Myxq94GnqaA7wNrAG6AK8At2RHUBmxs56MN06dOkWXLl0oWrQon3/+Oe3bt3c6JGP8kqdEUUxVX3c/3yEiP2VHQBmxs55MRr777jsaNGhAUFAQn376KaGhoVafyZhL4GmOopCI1BaROiJSByicajlDItJBRHaIyG4RGemhXX0RSfDm+gw768mk5/jx49x///00btyYd95x1a1s1KiRJQljLpGnHsUh4KUUy4dTLCvQ2tOG3TWhpgNtgRjgRxFZoqrb0mj3HPDFxYVuzDkff/wxDz30EEeOHGHUqFF0797d6ZCMyTU83bio1SVu+3pgt6ruARCRBbgq0G5L1W4w8BFQ/xL3Z/KoIUOGMGXKFCIiIli2bBm1a9d2OiRjchVvrqPIrErAgRTLMUCDlA1EpBJwM67eSbqJQkT6Af0ACl9+rV1HYVBVEhISCAwMpHPnzpQrV45hw4ZZfSZjfMCXV1indamrplqeAoxQ1QRPG1LVWapaT1XrJSB2HUUet3fvXjp06MCTTz4JQJs2bRg1apQlCWN8xJeJIga4IsVyZeBgqjb1gAUishe4DZghIjdltGG7jiJvSkxM5JVXXiE0NJT169dTpUoVp0MyJk/IcOhJXEVwegHXqOrT7vtlX66qP2Tw1h+BaiJyNfA70APombKBql6dYj9zgU9V9ZOMYrLrKPKeXbt2cd9997Fu3To6dOjAa6+9ZonCmGziTY9iBtAIuNO9fBLX2UweqWo8MAjX2UzbgQ9UNVpEBojIgEzGa9dR5FFnz57l119/5e2332bZsmWWJIzJRuK6HbaHBiI/qWodEdmsqrXdr/2squHZEmEqpasE61/7tjuxa5PNNm/ezOLFixk3bhwA//33HwULFnQ2KGP8lIhsUtV6mXmvNz2KOPe1Dure2WVAYmZ2Zow3zpw5w6hRo6hfvz4zZ87kyJEjAJYkjHGIN4liKrAIKCcizwLfAhN8GpXJs7799lvCw8OZOHEivXv3Ztu2bVx22WVOh2VMnpbhZLaqzheRTUAbXKe83qSqNvZjslxsbCzdunWjePHirFixgrZt2zodkjEG7856uhI4DSxN+Zqq7vdlYCbv+Pbbb2ncuDFFixbls88+IzQ0lKJFizodljHGzZuhp8+AT90/vwL2AMt9GZQnSXe4M/7v2LFj9O7dm2bNmiUX8WvYsKElCWNyGG/ucFdLVcPcP6vhquH0re9DS5vd4c7/qSoffvghISEhvPfeezz55JP06NHD6bCMMem46CuzVfUnHC7gZ1dm+7chQ4Zwxx13cMUVV7Bx40aefvppO6PJmBzMmzmKoSkW8wF1gCM+i8gLdmW2/1FV4uPjyZ8/P127dqVixYoMHTqUwEBf1qU0xmQFby64G5tiMR7YC3ykqmd8GFe6ilaurqvXbbArs/3Ib7/9Rr9+/ahbty4TJ050Ohxj8qRLueDO49c594V2RVV1eKYi8wG7w53/SEhIYNq0aYwePZqAgABuv/12p0MyxmRCuolCRAJVNd7b254ak9LOnTu59957+e677+jYsSMzZ87kiiuuyPiNxpgcx1OP4gdc8xGRIrIE+BA4lbRSVT/2cWzGj8XHx7Nv3z7mzZtHz549cRUhNsb4I29mEksDx3DdhU5xXZ2tgCUKc56NGzeyePFixo8fT0hICHv27LGzmYzJBTydHlvOfcZTFLDV/TPa/TMqG2IzfuLff//l8ccfp0GDBsyZM8eK+BmTy3hKFAFAUfejWIrnSQ9jWL16NWFhYbzwwgv06dOH6OhoK+JnTC7jaejpkKo+nW2RGL8TGxvLLbfcQsmSJfnqq69o3bq10yEZY3zAU6Kw2UeTprVr19KkSROKFi3K8uXLqVmzJkFBQU6HZYzxEU9DT22yLQrjF44ePcpdd91F8+bNk4v4XX/99ZYkjMnl0u1RqOpf2RmIyblUlQ8++IDBgwdz/Phxxo4da0X8jMlDrNCOydAjjzzCK6+8Qv369fnqq6+oVauW0yEZY7KRJQqTJlUlLi6OAgUKcPPNN1OlShUeffRRAgICnA7NGJPNMiwKmNOUrhKsf+2zO7H60q+//soDDzxAvXr1eP75550OxxiTBS6lKOBF34/C5F4JCQm89NJL1KpVi02bNlG9enWnQzLG5AA29GQA+OWXX7jnnnv44Ycf6NKlC6+++iqVKlVyOixjTA5gicIAkJiYyMGDB3nvvffo3r27FfEzxiTzu6GnswmJdr/sLPLDDz8wZswYAEJCQvj111/p0aOHJQljzHn8LlHEJSTSa/YGSxaX4PTp0wwbNoxGjRrx1ltvJRfxK1CggMORGWNyIr9LFABx8Yls2HPM6TD80qpVq6hVqxYvvvgiDzzwgBXxM8ZkyC/nKPIH5qPhNWWcDsPvxMbGcvvtt1OyZElWrVpFy5YtnQ7JGOMH/K5HkT8gH/P7NrT7Zl+Eb775hsTExOQiflu2bLEkYYzxmt8ligIB+SxJeOnIkSPceeedtGrVinnz5gFQv359ihQp4nBkxhh/4pdDT8YzVeW9997j4Ycf5uTJk4wfP96K+BljMs0SRS40ePBgpk+fTsOGDXnjjTcICQlxOiRjjB+zRJFLJCYmEh8fT4ECBbjtttuoWrUqgwcPtiJ+xphL5tM5ChHpICI7RGS3iIxMY30vEdnifqwXkXBfxpNb7dq1i9atWydfPNeyZUur9GqMyTI+SxQiEgBMBzoCIcCdIpJ6DOQ3oIWqhgHjgVm+iic3io+PZ9KkSYSFhREZGUlwcLDTIRljciFfDj1dD+xW1T0AIrIA6AZsS2qgqutTtN8AVPZhPLnK9u3b6d27Nxs3bqRbt27MmDGDihUrOh2WMSYX8uXQUyXgQIrlGPdr6ekDLE9rhYj0E5GNIrIxLi4uC0P0b3/88Qfvv/8+ixYtsiRhjPEZXyaKtCrLpXmXJBFphStRjEhrvarOUtV6qlovf/78WRiif9mwYQOjRo0CIDg4mF9//ZU77rjDivgZY3zKl4kiBrgixXJl4GDqRiISBswGuqmqFXBKw6lTpxgyZAiNGzdm/vz5yUX88nLSNMZkH18mih+BaiJytYgUAHoAS1I2EJErgY+Bu1V1pw9j8VsrV64kNDSUKVOmMHDgQCviZ4zJdj6bzFbVeBEZBHwBBABzVDVaRAa4178G/A8oA8xwD5/EZ/aerrlRbGwsPXr0oHTp0qxZs4ZmzZo5HZIxJg8S1TSnDXKs0lWC9a99250Ow6e+/vprWrRoQUBAAJs2bSIkJITChQs7HZYxxo+JyKbMfhH3u6KAudkff/zBHXfcQZs2bZKL+NWtW9eShDHGUZYocgBV5Z133iEkJITFixfz7LPP0rNnT6fDMsYYwGo95QgPPfQQr776Ko0aNeKNN96wK6yNMTmKJQqHJCYmEhcXR8GCBenevTvBwcEMHDjQ6jMZY3IcG3pywI4dO2jRokVyEb8WLVpYpVdjTI5liSIbxcXFMXHiRMLDw4mKiqJWrVpOh2SMMRmyoadsEh0dzd13383mzZu55ZZbmD59OpdffrnTYRljTIYsUWSTgIAA/vrrLxYuXMitt97qdDjGGOM1G3ryofXr1zNihKvOYY0aNdi9e7clCWOM37FE4QOxsbE8/PDDNG3alPfff5+jR48CEBhoHThjjP+xRJHFVqxYQWhoKNOmTWPQoEFERUVRtmxZp8MyxphMs6+4WSg2NpZevXpRpkwZ1q5dS5MmTZwOyRhjLpn1KLLAl19+SUJCAkWLFmXFihVERkZakjDG5BqWKC7BoUOHuPXWW2nXrh3z588HoHbt2hQqVMjhyIwxJutYosgEVWXu3LmEhITw2WefMXHiRCviZ4zJtWyOIhMefPBBZs6cSdOmTZk9ezbVq1d3OiSTA8XFxRETE8OZM2ecDsXkIYUKFaJy5cpZeqtkSxReSlnEr2fPnoSFhTFgwADy5bNOmUlbTEwMxYoV46qrrsJ9B0djfEpVOXbsGDExMVx99dVZtl37lPPC9u3badasGaNHjwagefPmDBw40JKE8ejMmTOUKVPGkoTJNiJCmTJlsrwXa590HsTFxTFhwgQiIiL45ZdfqF27ttMhGT9jScJkN1/8zdnQUzqio6O56667iIyM5Pbbb+eVV16hfPnyTodljDHZznoU6QgMDOTEiRN8/PHHfPDBB5YkjF8KCAggIiKC0NBQunTpwt9//528Ljo6mtatW3PddddRrVo1xo8fj6omr1++fDn16tUjODiYGjVqMGzYMAd+A882b95M3759nQ4jXWvWrKFOnToEBgaycOHCdNtt2rSJWrVqUbVqVR5++OHkf4f//vuP7t27U7VqVRo0aMDevXsBOHLkCB06dMiOXwGwRHGetWvXJv9nqF69Ojt37uTmm292OCqTl2zad5zpq3azad/xLNle4cKFiYyMJCoqitKlSzN9+nQA/v33X7p27crIkSPZuXMnP//8M+vXr2fGjBkAREVFMWjQIObNm8f27duJiorimmuuyZKYksTHx1/yNiZMmMDgwYOzdZ8X48orr2Tu3LkZnj7/4IMPMmvWLHbt2sWuXbv4/PPPAXjjjTcoVaoUu3fvZsiQIclFRi+77DIqVKjAunXrfP47gA09AXDy5ElGjhzJjBkzuPrqqxk5ciRly5a1In4myzy1NJptB//x2ObkmTh+OXySRIV8AjUuL0axQumf4hhSsThju9T0OoZGjRqxZcsWAN59912aNGlCu3btAChSpAjTpk2jZcuWPPTQQzz//POMGTOGGjVqAK4e9sCBAy/YZmxsLIMHD2bjxo2ICGPHjuXWW2+laNGixMbGArBw4UI+/fRT5s6dy7333kvp0qXZvHkzERERLFq0iMjISEqWLAlA1apVWbduHfny5WPAgAHs378fgClTplxQ7eDkyZNs2bKF8PBwAH744QceffRR/v33XwoXLsybb75J9erVmTt3Lp999hlnzpzh1KlTLF26lMGDB7N161bi4+MZN24c3bp1Y+/evdx9992cOnUKgGnTptG4cWOvj29arrrqKgCPJ74cOnSIf/75h0aNGgHQu3dvPvnkEzp27MjixYsZN24cALfddhuDBg1CVRERbrrpJubPn58tVSDy/Cfh8uXL6d+/PzExMTz66KM888wzBAUFOR2WyYP+ORNPonvkJ1Fdy54SxcVISEjgq6++ok+fPoBr2Klu3brntbn22muJjY3ln3/+ISoqisceeyzD7Y4fP54SJUqwdetWAI4fz7gntHPnTlauXElAQACJiYksWrSI++67j++//56rrrqK8uXL07NnT4YMGULTpk3Zv38/7du3Z/v27edtZ+PGjYSGhiYv16hRgzVr1hAYGMjKlSsZPXo0H330EQDfffcdW7ZsoXTp0owePZrWrVszZ84c/v77b66//npuuOEGypUrx5dffkmhQoXYtWsXd955Jxs3brwg/mbNmnHy5MkLXp80aRI33HBDhr9/ar///juVK1dOXq5cuTK///578rorrrgCcCXrEiVKcOzYMcqWLUu9evV44oknLnp/mZGnE8XJkyfp3bs35cqVY/369TRs2NDpkEwu5c03/037jtNr9gbi4hPJH5iPl3vUpm6VUpe033///ZeIiAj27t1L3bp1adu2LUDyt9K0XMxZMytXrmTBggXJy6VKZRzv7bffnnx/+O7du/P0009z3333sWDBArp375683W3btiW/559//uHkyZMUK1Ys+bVDhw5x2WWXJS+fOHGCe+65h127diEixMXFJa9r27YtpUuXBlwVnpcsWcKkSZMA12nM+/fvp2LFigwaNIjIyEgCAgLYuXNnmvGvXbs2w9/xYqScF0qS9G/gaV25cuU4ePBglsaSnjyXKFSVL774grZt21KsWDFWrlxJjRo1KFiwoNOhmTyubpVSzO/bkA17jtHwmjKXnCTg3BzFiRMn6Ny5M9OnT+fhhx+mZs2arFmz5ry2e/bsoWjRohQrVoyaNWuyadOm5GGd9KSXcFK+lvqc/pQ99kaNGrF7926OHDnCJ598kvwNOTExke+++47ChQt7/N1SbvvJJ5+kVatWLFq0iL1799KyZcs096mqfPTRRxdUVBg3bhzly5fn559/JjExMd2abVndo6hcuTIxMTHJyzExMVSsWDF53YEDB6hcuTLx8fGcOHEiOeGdOXPG4/HJSnlqMvvQoUPccsstdOzYMbmIX3h4uCUJk2PUrVKKh1pVzZIkkVKJEiWYOnUqkyZNIi4ujl69evHtt9+ycuVKwNXzePjhh3n88ccBGD58OBMmTEj+Vp2YmMhLL710wXbbtWvHtGnTkpeThp7Kly/P9u3bk4eW0iMi3HzzzQwdOpTg4GDKlCmT5nYjIyMveG9wcDC7d+9OXj5x4gSVKlUCYO7cuenus3379rzyyivJ39Y3b96c/P4KFSqQL18+3nnnHRISEtJ8/9q1a4mMjLzgkZkkAVChQgWKFSvGhg0bUFXefvttunXrBkDXrl156623ANdcT+vWrZOT8M6dO88bevOlPJEoVJU5c+YQHBzM559/zvPPP29F/EyeU7t2bcLDw1mwYAGFCxdm8eLFPPPMM1SvXp1atWpRv359Bg0aBEBYWBhTpkzhzjvvJDg4mNDQUA4dOnTBNp944gmOHz9OaGgo4eHhrFq1CoCJEyfSuXNnWrduTYUKFTzG1b17d+bNm5c87AQwdepUNm7cSFhYGCEhIbz22msXvK9GjRqcOHEi+dv9448/zqhRo2jSpEm6H/Lg6nnExcURFhZGaGgoTz75JAADBw7krbfeomHDhuzcuTNL5ip//PFHKleuzIcffkj//v2pWfPcEGRERETy81dffZW+fftStWpVrr32Wjp27AhAnz59OHbsGFWrVuWll15i4sSJye9ZtWoVnTp1uuQYvSFpjYHlZKWrBOtf+7Zn3DCF/v37M2vWLJo3b87s2bOpVq2aj6Iz5pzt27cTHBzsdBi52uTJkylWrFiOvpbCV5o3b87ixYvTnBdK629PRDapar3M7CvX9igSEhKSxy/vuusuXn31VVatWmVJwphc5MEHH8yTQ8dHjhxh6NChXp08kBVyZY8iOjqaPn360Lhx4zTHVY3JDtajME6xHoUHZ8+eZfz48dSuXZvdu3dTv359p0MyeZy/fREz/s8Xf3O55vTYrVu30qtXL7Zu3UqPHj2YOnXqeedYG5PdChUqxLFjx6zUuMk2SfejyOrbMeeaRFGgQAFOnz7N4sWL6dq1q9PhGJN8fvyRI0ecDsXkIUl3uMtKfj1HsXr1apYsWcKLL74IuCawk674NMYYc06OnaMQkQ4iskNEdovIyDTWi4hMda/fIiJ1vNnuP//8w4MPPkjLli355JNPOHr0KIAlCWOM8QGfJQoRCQCmAx2BEOBOEQlJ1awjUM396Ae8mtF2/z31D9fVCGbWrFkMHTqUrVu3UrZs2SyO3hhjTBJfzlFcD+xW1T0AIrIA6AZsS9GmG/C2usa/NohISRGpoKoXXgLqduavwySWvYI5H33OPTe19WH4xhhjwLeJohJwIMVyDNDAizaVgPMShYj0w9XjIF/h4pAvUPvcfefBe2OPHc7yqP1LWeCo00HkEHYszrFjcY4di3OqZ9wkbb5MFGmdD5h65tybNqjqLGAWgIhs/O/0iUxNyOQ2IrIxs5NTuY0di3PsWJxjx+IcEbnw5hpe8uVkdgxwRYrlykDq4unetDHGGOMgXyaKH4FqInK1iBQAegBLUrVZAvR2n/3UEDjhaX7CGGNM9vPZ0JOqxovIIOALIACYo6rRIjLAvf41YBlwI7AbOA3c58WmZ/koZH9kx+IcOxbn2LE4x47FOZk+Fn53wZ0xxpjslauKAhpjjMl6liiMMcZ4lGMTha/Kf/gjL45FL/cx2CIi60Uk3Ik4s0NGxyJFu/oikiAit2VnfNnJm2MhIi1FJFJEokVkdXbHmF28+D9SQkSWisjP7mPhzXyo3xGROSLyp4hEpbM+c5+bqprjHrgmv38FrgEKAD8DIana3Agsx3UtRkPge6fjdvBYNAZKuZ93zMvHIkW7r3GdLHGb03E7+HdRElclhCvdy+WcjtvBYzEaeM79/DLgL6CA07H74Fg0B+oAUemsz9TnZk7tUSSX/1DVs0BS+Y+Ukst/qOoGoKSIeL6Lu3/K8Fio6npVPe5e3IDrepTcyJu/C4DBwEfAn9kZXDbz5lj0BD5W1f0Aqppbj4c3x0KBYuK6MUhRXIkiPnvD9D1VXYPrd0tPpj43c2qiSK+0x8W2yQ0u9vfsg+sbQ26U4bEQkUrAzcBr2RiXE7z5u7gOKCUi34jIJhHpnW3RZS9vjsU0IBjXBb1bgUdUNTF7wstRMvW5mVNvXJRl5T9yAa9/TxFphStRNPVpRM7x5lhMAUaoakIuv6ucN8ciEKgLtAEKA9+JyAZV3enr4LKZN8eiPRAJtAauBb4UkbWq+o+PY8tpMvW5mVMThZX/OMer31NEwoDZQEdVPZZNsWU3b45FPWCBO0mUBW4UkXhV/SRbIsw+3v4fOaqqp4BTIrIGCAdyW6Lw5ljcB0xU10D9bhH5DagB/JA9IeYYmfrczKlDT1b+45wMj4WIXAl8DNydC78tppThsVDVq1X1KlW9ClgIDMyFSQK8+z+yGGgmIoEiUgRX9ebt2RxndvDmWOzH1bNCRMrjqqS6J1ujzBky9bmZI3sU6rvyH37Hy2PxP6AMMMP9TTpec2HFTC+PRZ7gzbFQ1e0i8jmwBUgEZqtqmqdN+jMv/y7GA3NFZCuu4ZcRqprryo+LyHtAS6CsiMQAY4H8cGmfm1bCwxhjjEc5dejJGGNMDmGJwhhjjEeWKIwxxnhkicIYY4xHliiMMcZ4ZInC5Ejuyq+RKR5XeWgbmwX7mysiv7n39ZOINMrENmaLSIj7+ehU69Zfaozu7SQdlyh3NdSSGbSPEJEbs2LfJu+y02NNjiQisapaNKvbetjGXOBTVV0oIu2ASaoadgnbu+SYMtquiLwF7FTVZz20vxeop6qDsjoWk3dYj8L4BREpKiJfub/tbxWRC6rGikgFEVmT4ht3M/fr7UTkO/d7PxSRjD7A1wBV3e8d6t5WlIg86n4tSEQ+c9/bIEpEurtf/0ZE6onIRKCwO4757nWx7p/vp/yG7+7J3CoiASLygoj8KK77BPT34rB8h7ugm4hcL657kWx2/6zuvkr5aaC7O5bu7tjnuPezOa3jaMwFnK6fbg97pPUAEnAVcYsEFuGqIlDcva4sritLk3rEse6fjwFj3M8DgGLutmuAIPfrI4D/pbG/ubjvXQHcDnyPq6DeViAIV2nqaKA2cCvweor3lnD//AbXt/fkmFK0SYrxZuAt9/MCuCp5Fgb6AU+4Xy8IbASuTiPO2BS/34dAB/dycSDQ/fwG4CP383uBaSnePwG4y/28JK66T0FO/3vbI2c/cmQJD2OAf1U1ImlBRPIDE0SkOa5yFJWA8sDhFO/5EZjjbvuJqkaKSAsgBFjnLm9SANc38bS8ICJPAEdwVeFtAyxSV1E9RORjoBnwOTBJRJ7DNVy19iJ+r+XAVBEpCHQA1qjqv+7hrjA5d0e+EkA14LdU7y8sIpHAVcAm4MsU7d8SkWq4qoHmT2f/7YCuIjLMvVwIuJLcWQPKZBFLFMZf9MJ1Z7K6qhonIntxfcglU9U17kTSCXhHRF4AjgNfquqdXuxjuKouTFoQkRvSaqSqO0WkLq6aOf8nIitU9WlvfglVPSMi3+Aqe90deC9pd8BgVf0ig038q6oRIlIC+BR4CJiKq5bRKlW92T3x/0067xfgVlXd4U28xoDNURj/UQL4050kWgFVUjcQkSruNq8Db+C6JeQGoImIJM05FBGR67zc5xrgJvd7gnANG60VkYrAaVWdB0xy7ye1OHfPJi0LcBVja4arkB3unw8mvUdErnPvM02qegJ4GBjmfk8J4Hf36ntTND2JawguyRfAYHF3r0Skdnr7MCaJJQrjL+YD9URkI67exS9ptGkJRIrIZlzzCC+r6hFcH5zvicgWXImjhjc7VNWfcM1d/IBrzmK2qm4GagE/uIeAxgDPpPH2WcCWpMnsVFbgurfxSnXduhNc9xLZBvwkIlHATDLo8btj+RlXWe3ncfVu1uGav0iyCghJmszG1fPI744tyr1sjEd2eqwxxhiPrEdhjDHGI0sUxhhjPLJEYYwxxiNLFMYYYzyyRGGMMcYjSxTGGGM8skRhjDHGo/8Hubsm380F2pAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curves and AUC\n",
    "plt.plot(fpr,tpr ,marker='.', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Inceptionv3 Fine-Tuning')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Inceptionv3_Fine_Tuning.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0550a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9902296535052377\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred,normalize = True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6239dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910541363091396\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3862f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score[:,1])\n",
    "auc = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53f7c4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(recall, precision, marker='.', label='Logistic')\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm \n",
    "#representation learning --> more practical, more adaptive to the dataset, baby in whatever scenario or world, very general, only need to know the basics and how to survive. \n",
    "#fintuning --> more intuitive. Fine tuning --> for this dataset, very familiar. Can't include everything, can't generalize everything"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
